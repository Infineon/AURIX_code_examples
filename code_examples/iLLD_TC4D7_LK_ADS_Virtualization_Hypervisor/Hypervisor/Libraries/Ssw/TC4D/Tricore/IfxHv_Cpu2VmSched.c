/**********************************************************************************************************************
 * \file IfxHv_Cpu2VmSched.c
 * \copyright Copyright (C) Infineon Technologies AG 2019
 *
 * Use of this file is subject to the terms of use agreed between (i) you or the company in which ordinary course of
 * business you are acting and (ii) Infineon Technologies AG or its licensees. If and as long as no such terms of use
 * are agreed, use of this file is subject to following:
 *
 * Boost Software License - Version 1.0 - August 17th, 2003
 *
 * Permission is hereby granted, free of charge, to any person or organization obtaining a copy of the software and
 * accompanying documentation covered by this license (the "Software") to use, reproduce, display, distribute, execute,
 * and transmit the Software, and to prepare derivative works of the Software, and to permit third-parties to whom the
 * Software is furnished to do so, all subject to the following:
 *
 * The copyright notices in the Software and this entire statement, including the above license grant, this restriction
 * and the following disclaimer, must be included in all copies of the Software, in whole or in part, and all
 * derivative works of the Software, unless such copies or derivative works are solely in the form of
 * machine-executable object code generated by a source language processor.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
 * WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
 * COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN
 * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 * IN THE SOFTWARE.
 *********************************************************************************************************************/

/*******************************************************************************
**                      Includes                                              **
*******************************************************************************/
#include "Ifx_Cfg.h"
#include "IfxHv_CpuVmSched.h"
#if (IFX_DEBUG_PRINT == 1U)
#include "printf_to_tspi.h"
#endif

/*******************************************************************************
**                       Types & Globals                                      **
*******************************************************************************/
VmDataType Tc2_Vm1;
VmDataType Tc2_Vm2;
VmDataType Tc2_Vm3;
VmDataType Tc2_Vm4;
VmDataType Tc2_Vm5;
VmDataType Tc2_Vm6;
VmDataType Tc2_Vm7;
HvDataType Tc2_Hv;

Hr2Context Tc2_Vm2_Context;
Hr2Context Tc2_Vm3_Context;
Hr2Context Tc2_Vm4_Context;
Hr2Context Tc2_Vm5_Context;
Hr2Context Tc2_Vm6_Context;
Hr2Context Tc2_Vm7_Context;

/*module globals*/
IFX_SSW_CORE_LINKER_SYMBOLS(2, 0);
#if (IFX_CFG_HV0_TIME_BASED_SCHD != 0U)
static volatile uint32 g_stmTicks[IFX_NUM_VM];
#endif

/*******************************************************************************
**                       Prototypes & Externals                               **
*******************************************************************************/
/** !IMPORTANT: The SSW Configuration shall be defined at Application SW Configuration
 * Please refer to iLLD demos for startup sw configuration (Ifx_Cfg_Ssw.c and .h)
 */
IFXHV_INLINE void Core2_vm1_start(void);
IFXHV_INLINE void Core2_vm2_start(void);
IFXHV_INLINE void Core2_vm3_start(void);
IFXHV_INLINE void Core2_vm4_start(void);
IFXHV_INLINE void Core2_vm5_start(void);
IFXHV_INLINE void Core2_vm6_start(void);
IFXHV_INLINE void Core2_vm7_start(void);

IFX_SSW_COMMON_LINKER_SYMBOLS();

/*******************************************************************************
**                       Defines                                              **
*******************************************************************************/

/*Add options to eliminate usage of stack pointers unnecessarily*/
#if defined(__HIGHTEC__) && !defined(__clang__)
#pragma GCC optimize ("-O1")
#elif defined(__TASKING__)
#pragma optimize R
#endif

/*Function to setup Hypervisor execution environment and start HV (VM0)*/
void core2_vm0_start(void)
{
    /*
     * !!WATCHDOG0 IS DISABLED HERE!!
     * Enable the watchdog in the demo if it is required and also service the watchdog periodically
     * */
    IfxHv_disableCpuWatchdog();

    /* Initialize the VMs to init state */
    Tc2_Vm1.State = VM_INIT;
    Tc2_Vm2.State = VM_INIT;
    Tc2_Vm3.State = VM_INIT;
    Tc2_Vm4.State = VM_INIT;
    Tc2_Vm5.State = VM_INIT;
    Tc2_Vm6.State = VM_INIT;
    Tc2_Vm7.State = VM_INIT;

    /*
     * Setup the L2 Mpu ranges to be used in the demonstrator
     * 1. PRS0 is used by hypervisor and associated trap locations.
     * 2. PRS1 is used by VM1.
     * 3. PRS2 is used by VM2.
     * 4. PRS3 is used by VM3.
     * 5. PRS4 is used by VM4.
     * 6. PRS5 is used by VM5.
     * 7. PRS6 is used by VM6.
     * 8. PRS7 is used by VM7.
     * */

    /*Hv code ranges*/
    IFXHV_MTCR(CPU_CPR0_L, HvMpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_CPR0_U, HvMpuConfig.code_cached.upperLimit);
    IFXHV_MTCR(CPU_CPR1_L, HvMpuConfig.code_noncached.lowerLimit);
    IFXHV_MTCR(CPU_CPR1_U, HvMpuConfig.code_noncached.upperLimit);

    /*Vm1 code ranges*/
    IFXHV_MTCR(CPU_CPR2_L, Hv_Vm1MpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_CPR2_U, Hv_Vm1MpuConfig.code_cached.upperLimit);
    IFXHV_MTCR(CPU_CPR3_L, Hv_Vm1MpuConfig.code_noncached.lowerLimit);
    IFXHV_MTCR(CPU_CPR3_U, Hv_Vm1MpuConfig.code_noncached.upperLimit);

    /*Vm2 code ranges*/
    IFXHV_MTCR(CPU_CPR4_L, Hv_Vm2MpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_CPR4_U, Hv_Vm2MpuConfig.code_cached.upperLimit);
    IFXHV_MTCR(CPU_CPR5_L, Hv_Vm2MpuConfig.code_noncached.lowerLimit);
    IFXHV_MTCR(CPU_CPR5_U, Hv_Vm2MpuConfig.code_noncached.upperLimit);

    /*Vm3 code ranges*/
    IFXHV_MTCR(CPU_CPR6_L, Hv_Vm3MpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_CPR6_U, Hv_Vm3MpuConfig.code_cached.upperLimit);
    IFXHV_MTCR(CPU_CPR7_L, Hv_Vm3MpuConfig.code_noncached.lowerLimit);
    IFXHV_MTCR(CPU_CPR7_U, Hv_Vm3MpuConfig.code_noncached.upperLimit);

    /*Vm4 code ranges*/
    IFXHV_MTCR(CPU_CPR8_L, Hv_Vm4MpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_CPR8_U, Hv_Vm4MpuConfig.code_cached.upperLimit);
    IFXHV_MTCR(CPU_CPR9_L, Hv_Vm4MpuConfig.code_noncached.lowerLimit);
    IFXHV_MTCR(CPU_CPR9_U, Hv_Vm4MpuConfig.code_noncached.upperLimit);

    /*Vm5 code ranges*/
    IFXHV_MTCR(CPU_CPR10_L, Hv_Vm5MpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_CPR10_U, Hv_Vm5MpuConfig.code_cached.upperLimit);
    IFXHV_MTCR(CPU_CPR11_L, Hv_Vm5MpuConfig.code_noncached.lowerLimit);
    IFXHV_MTCR(CPU_CPR11_U, Hv_Vm5MpuConfig.code_noncached.upperLimit);

    /*Vm6 code ranges*/
    IFXHV_MTCR(CPU_CPR12_L, Hv_Vm6MpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_CPR12_U, Hv_Vm6MpuConfig.code_cached.upperLimit);
    IFXHV_MTCR(CPU_CPR13_L, Hv_Vm6MpuConfig.code_noncached.lowerLimit);
    IFXHV_MTCR(CPU_CPR13_U, Hv_Vm6MpuConfig.code_noncached.upperLimit);

    /*Vm7 code ranges*/
    IFXHV_MTCR(CPU_CPR14_L, Hv_Vm7MpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_CPR14_U, Hv_Vm7MpuConfig.code_cached.upperLimit);
    IFXHV_MTCR(CPU_CPR15_L, Hv_Vm7MpuConfig.code_noncached.lowerLimit);
    IFXHV_MTCR(CPU_CPR15_U, Hv_Vm7MpuConfig.code_noncached.upperLimit);

    /*SFR data ranges*/
    IFXHV_MTCR(CPU_DPR0_L, 0xf0000000);
    IFXHV_MTCR(CPU_DPR0_U, 0xffffffff);

    /*Hv data ranges*/
    IFXHV_MTCR(CPU_DPR1_L, HvMpuConfig.data_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR1_U, HvMpuConfig.data_cached.upperLimit);
    IFXHV_MTCR(CPU_DPR2_L, HvMpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR2_U, HvMpuConfig.code_cached.upperLimit);

    /* Data range for VM1 */
    IFXHV_MTCR(CPU_DPR3_L, Hv_Vm1MpuConfig.data_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR3_U, Hv_Vm1MpuConfig.data_cached.upperLimit);
    IFXHV_MTCR(CPU_DPR4_L, Hv_Vm1MpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR4_U, Hv_Vm1MpuConfig.code_cached.upperLimit);

    /* Data range for VM2 */
    IFXHV_MTCR(CPU_DPR5_L, Hv_Vm2MpuConfig.data_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR5_U, Hv_Vm2MpuConfig.data_cached.upperLimit);
    IFXHV_MTCR(CPU_DPR6_L, Hv_Vm2MpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR6_U, Hv_Vm2MpuConfig.code_cached.upperLimit);

    /* Data range for VM3 */
    IFXHV_MTCR(CPU_DPR7_L, Hv_Vm3MpuConfig.data_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR7_U, Hv_Vm3MpuConfig.data_cached.upperLimit);
    IFXHV_MTCR(CPU_DPR8_L, Hv_Vm3MpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR8_U, Hv_Vm3MpuConfig.code_cached.upperLimit);

    /* Data range for VM4 */
    IFXHV_MTCR(CPU_DPR9_L, Hv_Vm4MpuConfig.data_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR9_U, Hv_Vm4MpuConfig.data_cached.upperLimit);
    IFXHV_MTCR(CPU_DPR10_L, Hv_Vm4MpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR10_U, Hv_Vm4MpuConfig.code_cached.upperLimit);

    /* Data range for VM5 */
    IFXHV_MTCR(CPU_DPR11_L, Hv_Vm5MpuConfig.data_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR11_U, Hv_Vm5MpuConfig.data_cached.upperLimit);
    IFXHV_MTCR(CPU_DPR12_L, Hv_Vm5MpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR12_U, Hv_Vm5MpuConfig.code_cached.upperLimit);

    /* Data range for VM6 */
    IFXHV_MTCR(CPU_DPR13_L, Hv_Vm6MpuConfig.data_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR13_U, Hv_Vm6MpuConfig.data_cached.upperLimit);
    IFXHV_MTCR(CPU_DPR14_L, Hv_Vm6MpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR14_U, Hv_Vm6MpuConfig.code_cached.upperLimit);

    /* Data range for VM7 */
    IFXHV_MTCR(CPU_DPR15_L, Hv_Vm7MpuConfig.data_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR15_U, Hv_Vm7MpuConfig.data_cached.upperLimit);
    IFXHV_MTCR(CPU_DPR16_L, Hv_Vm7MpuConfig.code_cached.lowerLimit);
    IFXHV_MTCR(CPU_DPR16_U, Hv_Vm7MpuConfig.code_cached.upperLimit);

    /*Hv Prs set*/
    IFXHV_MTCR(CPU_DPWE_0, 0x3U);
    IFXHV_MTCR(CPU_DPRE_0, 0x7U);
    IFXHV_MTCR(CPU_CPXE_0, 0x3U);

    /*Vm1 Prs set*/
    IFXHV_MTCR(CPU_DPWE_1, 0x9U);
    IFXHV_MTCR(CPU_DPRE_1, 0x19U);
    IFXHV_MTCR(CPU_CPXE_1, 0xCU);

    /*Vm2 Prs set*/
    IFXHV_MTCR(CPU_DPWE_2, 0x21U);
    IFXHV_MTCR(CPU_DPRE_2, 0x61U);
    IFXHV_MTCR(CPU_CPXE_2, 0x30U);

    /*Vm3 Prs set*/
    IFXHV_MTCR(CPU_DPWE_3, 0x81U);
    IFXHV_MTCR(CPU_DPRE_3, 0x181U);
    IFXHV_MTCR(CPU_CPXE_3, 0xC0U);

    /*Vm4 Prs set*/
    IFXHV_MTCR(CPU_DPWE_4, 0x201U);
    IFXHV_MTCR(CPU_DPRE_4, 0x601U);
    IFXHV_MTCR(CPU_CPXE_4, 0x300U);

    /*Vm5 Prs set*/
    IFXHV_MTCR(CPU_DPWE_5, 0x801U);
    IFXHV_MTCR(CPU_DPRE_5, 0x1801U);
    IFXHV_MTCR(CPU_CPXE_5, 0xC00U);

    /*Vm6 Prs set*/
    IFXHV_MTCR(CPU_DPWE_6, 0x2001U);
    IFXHV_MTCR(CPU_DPRE_6, 0x6001U);
    IFXHV_MTCR(CPU_CPXE_6, 0x3000U);

    /*Vm7 Prs set*/
    IFXHV_MTCR(CPU_DPWE_7, 0x8001U);
    IFXHV_MTCR(CPU_DPRE_7, 0x18001U);
    IFXHV_MTCR(CPU_CPXE_7, 0xC000U);

#if (IFX_CFG_HV2_TIME_BASED_SCHD != 0U)

    /* CMCON register for Comparator 0
     * SRC init. for interrupt
     * Clear ICSR for Comparator 0
     * Enable interrupt in ICR for Comparator 0, IRQ0
     * Configure CMP0 with current value + ticks
     */

    Ifx_CPU_STM_CMCON cmcon;
    Ifx_CPU_STM_ICR   icr;
    Ifx_SRC_SRCR      srcTmp;

    /* Convert execution time of each VMs to ticks.
     * Store it in a variable to avoid runtime calculation in scheduler */
    g_stmTicks[0]                 = IFX_CORE2_VM1_EXECUTION_TIME * IfxHv_getStmFrequency();
    g_stmTicks[1]                 = IFX_CORE2_VM2_EXECUTION_TIME * IfxHv_getStmFrequency();
    g_stmTicks[2]                 = IFX_CORE2_VM3_EXECUTION_TIME * IfxHv_getStmFrequency();
    g_stmTicks[3]                 = IFX_CORE2_VM4_EXECUTION_TIME * IfxHv_getStmFrequency();
    g_stmTicks[4]                 = IFX_CORE2_VM5_EXECUTION_TIME * IfxHv_getStmFrequency();
    g_stmTicks[5]                 = IFX_CORE2_VM6_EXECUTION_TIME * IfxHv_getStmFrequency();
    g_stmTicks[6]                 = IFX_CORE2_VM7_EXECUTION_TIME * IfxHv_getStmFrequency();

    cmcon.U                       = CPU2_STMHV_VM0_CMCON.U;
    icr.U                         = CPU2_STMHV_VM0_STM_ICR.U;

    cmcon.B.MSIZE0                = IfxHv2_StmConfig.compareSize;
    cmcon.B.MSTART0               = IfxHv2_StmConfig.compareOffset;
    cmcon.B.RELCOMP0              = IfxHv2_StmConfig.comparison;
    CPU2_STMHV_VM0_CMCON.U        = cmcon.U;

    srcTmp.U                      = SRC_STMCPU2_SR0.U;

    srcTmp.B.SRPN                 = IfxHv2_StmConfig.triggerPriority;
    srcTmp.B.TOS                  = IfxHv2_StmConfig.typeOfService;
    srcTmp.B.VM                   = IfxHv2_StmConfig.vmId;
    srcTmp.B.SRE                  = 1U;

    SRC_STMCPU2_SR0.U             = srcTmp.U;
    CPU2_STMHV_VM0_ISCR.B.CMP0IRR = 1U;

    icr.B.CMP0EN                  = 1U;
    icr.B.CMP0OS                  = IfxHv2_StmConfig.comparatorInterrupt;

    CPU2_STMHV_VM0_STM_ICR.U      = icr.U;
    CPU2_STMHV_VM0_CMP0.U         = (uint32)((CPU2_STM_ABS.U >> IfxHv2_StmConfig.compareOffset) + g_stmTicks[0]);

    /* Enable interrupts by setting the IE bit */
    IFXHV_ENABLE_INTERRUPT();
#endif

    /* Enable IR hardware virtualisation support */
    MODULE_INT.ICU[2].VMEN.U = (IFX_CFG_TC2_VM1_INT << IFX_INT_ICU_VMEN_VM1_OFF) | (IFX_CFG_TC2_VM2_INT << IFX_INT_ICU_VMEN_VM2_OFF) | \
                               (IFX_CFG_TC2_VM3_INT << IFX_INT_ICU_VMEN_VM3_OFF) | (IFX_CFG_TC2_VM4_INT << IFX_INT_ICU_VMEN_VM4_OFF) | \
                               (IFX_CFG_TC2_VM5_INT << IFX_INT_ICU_VMEN_VM5_OFF) | (IFX_CFG_TC2_VM6_INT << IFX_INT_ICU_VMEN_VM6_OFF) | \
                               (IFX_CFG_TC2_VM7_INT << IFX_INT_ICU_VMEN_VM7_OFF) | 1u;

    /* Threshold configuration */
    IFXHV_MTCR(CPU_VM1_PETHRESH, IfxHv2_VmThresholdConfig.vm1ThresholdVal);
    IFXHV_MTCR(CPU_VM2_PETHRESH, IfxHv2_VmThresholdConfig.vm2ThresholdVal);
    IFXHV_MTCR(CPU_VM3_PETHRESH, IfxHv2_VmThresholdConfig.vm3ThresholdVal);
    IFXHV_MTCR(CPU_VM4_PETHRESH, IfxHv2_VmThresholdConfig.vm4ThresholdVal);
    IFXHV_MTCR(CPU_VM5_PETHRESH, IfxHv2_VmThresholdConfig.vm5ThresholdVal);
    IFXHV_MTCR(CPU_VM6_PETHRESH, IfxHv2_VmThresholdConfig.vm6ThresholdVal);
    IFXHV_MTCR(CPU_VM7_PETHRESH, IfxHv2_VmThresholdConfig.vm7ThresholdVal);

    /*Start VM1*/
    Core2_vm1_start();
}


/* Function to start VM1 by moving execution context to hardware resource set 1 */
IFXHV_INLINE void Core2_vm1_start(void)
{
    /*
     * 1. Set VM1 to Run.
     * 2. Select PRS1 and VM1
     * 3. Set A11 to VM1 reset address
     * 4. Initialize PCXI to CSA start of VM1
     * 5. Call RFH
     * */

    Tc2_Hv.CurrRunningVm = HV_VM1;
    Tc2_Vm1.State        = VM_RUN;
    IFXHV_MTCR(CPU_VCON2, (VM1 | (PRS1 << 8u)));
    IFXHV_SETA11((void *)__START21);

    /* CSA nodes locations inside HV are reserved storing VM1's context
     * in case of VM1 is paused and switched. Same location shall be used before re-scheduling the VM1.
     * Care shall be done, to avoid corruption of these locations when HV (VM0) is active.*/
    Hv_setCsaAddress((__CSA20), HV_VM1);
    IFXHV_RFH();
}


/* Function to start VM2 by moving execution context to hardware resource set 2 */
IFXHV_INLINE void Core2_vm2_start(void)
{
    /*
     * 1. Set VM2 to Run.
     * 2. Select PRS2 and VM2
     * 3. Set A11 to VM2 reset address
     * 4. Initialize PCXI to CSA start of VM2
     * 5. Call RFH
     * */

    Tc2_Hv.CurrRunningVm = HV_VM2;
    Tc2_Vm2.State        = VM_RUN;
    IFXHV_MTCR(CPU_VCON2, (VM2 | (PRS2 << 8u)));
    IFXHV_SETA11((void *)__START22);

    /* CSA nodes locations inside HV are reserved storing VM2's context
     * in case of VM2 is paused and switched. Same location shall be used before re-scheduling the VM2.
     * Care shall be done, to avoid corruption of these locations when HV (VM0) is active.*/
    Hv_setCsaAddress((__CSA20), HV_VM2);
    IFXHV_RFH();
}


/* Function to start VM3 by moving execution context to hardware resource set 2 */
IFXHV_INLINE void Core2_vm3_start(void)
{
    /*
     * 1. Set VM3 to Run.
     * 2. Select PRS3 and VM3
     * 3. Set A11 to VM3 reset address
     * 4. Initialize PCXI to CSA start of VM3
     * 5. Call RFH
     * */

    Tc2_Hv.CurrRunningVm = HV_VM3;
    Tc2_Vm3.State        = VM_RUN;
    IFXHV_MTCR(CPU_VCON2, (VM3 | (PRS3 << 8u)));
    IFXHV_SETA11((void *)__START23);

    /* CSA nodes locations inside HV are reserved storing VM3's context
     * in case of VM3 is paused and switched. Same location shall be used before re-scheduling the VM3.
     * Care shall be done, to avoid corruption of these locations when HV (VM0) is active.*/
    Hv_setCsaAddress((__CSA20), HV_VM3);
    IFXHV_RFH();
}


/* Function to start VM4 by moving execution context to hardware resource set 2 */
IFXHV_INLINE void Core2_vm4_start(void)
{
    /*
     * 1. Set VM4 to Run.
     * 2. Select PRS4 and VM4
     * 3. Set A11 to VM4 reset address
     * 4. Initialize PCXI to CSA start of VM4
     * 5. Call RFH
     * */

    Tc2_Hv.CurrRunningVm = HV_VM4;
    Tc2_Vm4.State        = VM_RUN;
    IFXHV_MTCR(CPU_VCON2, (VM4 | (PRS4 << 8u)));
    IFXHV_SETA11((void *)__START24);

    /* CSA nodes locations inside HV are reserved storing VM4's context
     * in case of VM4 is paused and switched. Same location shall be used before re-scheduling the VM4.
     * Care shall be done, to avoid corruption of these locations when HV (VM0) is active.*/
    Hv_setCsaAddress((__CSA20), HV_VM4);
    IFXHV_RFH();
}


/* Function to start VM5 by moving execution context to hardware resource set 2 */
IFXHV_INLINE void Core2_vm5_start(void)
{
    /*
     * 1. Set VM5 to Run.
     * 2. Select PRS5 and VM5
     * 3. Set A11 to VM5 reset address
     * 4. Initialize PCXI to CSA start of VM5
     * 5. Call RFH
     * */

    Tc2_Hv.CurrRunningVm = HV_VM5;
    Tc2_Vm5.State        = VM_RUN;
    IFXHV_MTCR(CPU_VCON2, (VM5 | (PRS5 << 8u)));
    IFXHV_SETA11((void *)__START25);

    /* CSA nodes locations inside HV are reserved storing VM5's context
     * in case of VM5 is paused and switched. Same location shall be used before re-scheduling the VM5.
     * Care shall be done, to avoid corruption of these locations when HV (VM0) is active.*/
    Hv_setCsaAddress((__CSA20), HV_VM5);
    IFXHV_RFH();
}


/* Function to start VM6 by moving execution context to hardware resource set 2 */
IFXHV_INLINE void Core2_vm6_start(void)
{
    /*
     * 1. Set VM6 to Run.
     * 2. Select PRS6 and VM6
     * 3. Set A11 to VM6 reset address
     * 4. Initialize PCXI to CSA start of VM6
     * 5. Call RFH
     * */

    Tc2_Hv.CurrRunningVm = HV_VM6;
    Tc2_Vm6.State        = VM_RUN;
    IFXHV_MTCR(CPU_VCON2, (VM6 | (PRS6 << 8u)));
    IFXHV_SETA11((void *)__START26);

    /* CSA nodes locations inside HV are reserved storing VM6's context
     * in case of VM6 is paused and switched. Same location shall be used before re-scheduling the VM6.
     * Care shall be done, to avoid corruption of these locations when HV (VM0) is active.*/
    Hv_setCsaAddress((__CSA20), HV_VM6);
    IFXHV_RFH();
}


/* Function to start VM7 by moving execution context to hardware resource set 2 */
IFXHV_INLINE void Core2_vm7_start(void)
{
    /*
     * 1. Set VM7 to Run.
     * 2. Select PRS7 and VM7
     * 3. Set A11 to VM7 reset address
     * 4. Initialize PCXI to CSA start of VM7
     * 5. Call RFH
     * */

    Tc2_Hv.CurrRunningVm = HV_VM7;
    Tc2_Vm7.State        = VM_RUN;
    IFXHV_MTCR(CPU_VCON2, (VM7 | (PRS7 << 8u)));
    IFXHV_SETA11((void *)__START27);

    /* CSA nodes locations inside HV are reserved storing VM7's context
     * in case of VM7 is paused and switched. Same location shall be used before re-scheduling the VM7.
     * Care shall be done, to avoid corruption of these locations when HV (VM0) is active.*/
    Hv_setCsaAddress((__CSA20), HV_VM7);
    IFXHV_RFH();
}


/***************************************************************************************
 *                                  VM Scheduler
 ***************************************************************************************
 *
 *             __________
 *            |          |
 *            |          |
 *            | HV INIT  |
 *            |          |
 *            |__________|
 *                 |
 *                 |
 *              ___X_____                 ___________                  _________
 *             |         |               |           |                |         |
 *             |         |-------------->|    HV     |--------------->|         |
 *             |   VM1   |               | SCHEDULER |                |   VM2   |
 *             |         |<--------------|           |<---------------|         |
 *             |_________|               |___________|                |_________|
 *
 * This state diagram defines overview of VM Scheduler
 * */

/* The Scheduler changes VM1 and VM2 in two different modes:
 * 1. Cooperative manner - each VM relinquishes the control by calling HVCALL(voluntary)
 * 2. Timer Event - Force as timer event is directly routed to HV (VM0-ISR)*/
void Hv2_Vm_PreEmptionScheduler(void)
{
    uint8 vmNum = 0U;
    vmNum = (uint8)Ifx_Ssw_getD15();

    if (Tc2_Hv.CurrRunningVm == HV_VM1)
    {
        Ifx_Hv_saveVmState(&Tc2_Vm1);
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM2)
    {
        Ifx_Hv_saveVmState(&Tc2_Vm2);
        /* STORE the VM2 context in memory before starting VM3, Since VM3 shares the same HR as VM2 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm2_Context);
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM3)
    {
        Ifx_Hv_saveVmState(&Tc2_Vm3);
        /* STORE the VM3 context in memory before starting VM4, Since VM4 shares the same HR as VM3 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm3_Context);
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM4)
    {
        Ifx_Hv_saveVmState(&Tc2_Vm4);
        /* STORE the VM4 context in memory before starting VM5, Since VM5 shares the same HR as VM4 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm4_Context);
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM5)
    {
        Ifx_Hv_saveVmState(&Tc2_Vm5);
        /* STORE the VM5 context in memory before starting VM6, Since VM6 shares the same HR as VM5 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm5_Context);
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM6)
    {
        Ifx_Hv_saveVmState(&Tc2_Vm6);
        /* STORE the VM6 context in memory before starting VM7, Since VM7 shares the same HR as VM6 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm6_Context);
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM7)
    {
        Ifx_Hv_saveVmState(&Tc2_Vm7);
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm7_Context);
    }

    switch (vmNum)
    {
    case 1:
        Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm1, VM1);
        break;
    case 2:
        Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm2_Context);
        Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm2, VM2);
        break;
    case 3:
        Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm3_Context);
        Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm3, VM3);
        break;
    case 4:
        Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm4_Context);
        Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm4, VM4);
        break;
    case 5:
        Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm5_Context);
        Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm5, VM5);
        break;
    case 6:
        Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm6_Context);
        Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm6, VM6);
        break;
    case 7:
        Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm7_Context);
        Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm7, VM7);
        break;
    default:
        break;
    }

    /*
     * 1. Restore the lower context for the incoming VM
     * 2. Execute RFH
     */
    __asm("rslcx");
    IFXHV_RFH();
}


#if (IFX_CFG_HV2_TIME_BASED_SCHD == 0U)
void Hv2_Vm_Scheduler(void)
{
    /* Detect VM which was running so far, to save its context before scheduling another VM */
    if (Tc2_Hv.CurrRunningVm == HV_VM1)
    {
        /* Save context information of VM1
         */
        Ifx_Hv_saveVmState(&Tc2_Vm1);

        /*
         * VM1 is always scheduled first during start-up. VM2 is scheduled only after 1st execution slot of VM1
         * is complete. Therefore, when schedule enters for the 1st time it shall check if VM2 start-up
         * is already complete.
         */
        if (Tc2_Vm2.State == VM_INIT)
        {
            /* Start VM2 */
            Core2_vm2_start();
        }
        else
        {
            /* RESTORE CONTEXT OF HR2/VM2 since VM3 was previously executing in HR2 */
            Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm2_Context);
            Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm2, VM2);
        }
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM2)
    {
        /* Save context information of VM2 */
        Ifx_Hv_saveVmState(&Tc2_Vm2);

        /* STORE the VM2 context in memory before starting VM3, Since VM3 shares the same HR as VM2 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm2_Context);

        /*
         * VM3 is scheduled only after 1st execution slot of VM2
         * is complete. Therefore, when schedule enters for the 1st time it shall check if VM3 start-up
         * is already complete.
         */
        if (Tc2_Vm3.State == VM_INIT)
        {
            Ifx_Ssw_Hv_resetHr2Context(&Tc2_Vm3_Context);
            /* Start VM3 */
            Core2_vm3_start();
        }
        else
        {
            /* RESTORE VM3 context before VM3 re-scheduling */
            Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm3_Context);
            Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm3, VM3);
        }
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM3)
    {
        /* Save context information of VM3 */
        Ifx_Hv_saveVmState(&Tc2_Vm3);

        /* STORE the VM3 context in memory before starting VM4, Since VM4 shares the same HR as VM3 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm3_Context);

        /*
         * VM4 is scheduled only after 1st execution slot of VM3
         * is complete. Therefore, when schedule enters for the 1st time it shall check if VM4 start-up
         * is already complete.
         */
        if (Tc2_Vm4.State == VM_INIT)
        {
            Ifx_Ssw_Hv_resetHr2Context(&Tc2_Vm4_Context);
            /* Start VM4 */
            Core2_vm4_start();
        }
        else
        {
            /* RESTORE VM4 context before VM4 re-scheduling */
            Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm4_Context);
            Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm4, VM4);
        }
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM4)
    {
        /* Save context information of VM4 */
        Ifx_Hv_saveVmState(&Tc2_Vm4);

        /* STORE the VM4 context in memory before starting VM5, Since VM5 shares the same HR as VM2 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm4_Context);

        /*
         * VM5 is scheduled only after 1st execution slot of VM4
         * is complete. Therefore, when schedule enters for the 1st time it shall check if VM5 start-up
         * is already complete.
         */
        if (Tc2_Vm5.State == VM_INIT)
        {
            Ifx_Ssw_Hv_resetHr2Context(&Tc2_Vm5_Context);
            /* Start VM5 */
            Core2_vm5_start();
        }
        else
        {
            /* RESTORE VM5 context before VM5 re-scheduling */
            Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm5_Context);
            Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm5, VM5);
        }
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM5)
    {
        /* Save context information of VM5 */
        Ifx_Hv_saveVmState(&Tc2_Vm5);

        /* STORE the VM5 context in memory before starting VM6, Since VM6 shares the same HR as VM5 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm5_Context);

        /*
         * VM6 is scheduled only after 1st execution slot of VM5
         * is complete. Therefore, when schedule enters for the 1st time it shall check if VM6 start-up
         * is already complete.
         */
        if (Tc2_Vm6.State == VM_INIT)
        {
            Ifx_Ssw_Hv_resetHr2Context(&Tc2_Vm6_Context);
            /* Start VM6 */
            Core2_vm6_start();
        }
        else
        {
            /* RESTORE VM6 context before VM6 re-scheduling */
            Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm6_Context);
            Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm6, VM6);
        }
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM6)
    {
        /* Save context information of VM6 */
        Ifx_Hv_saveVmState(&Tc2_Vm6);

        /* STORE the VM6 context in memory before starting VM7, Since VM7 shares the same HR as VM6 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm6_Context);

        /*
         * VM7 is scheduled only after 1st execution slot of VM6
         * is complete. Therefore, when schedule enters for the 1st time it shall check if VM7 start-up
         * is already complete.
         */
        if (Tc2_Vm7.State == VM_INIT)
        {
            Ifx_Ssw_Hv_resetHr2Context(&Tc2_Vm7_Context);
            /* Start VM6 */
            Core2_vm7_start();
        }
        else
        {
            /* RESTORE VM7 context before VM7 re-scheduling */
            Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm7_Context);
            Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm7, VM7);
        }
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM7)
    {
        /* Save context information of VM7 */
        Ifx_Hv_saveVmState(&Tc2_Vm7);

        /* STORE the VM7 context in memory before starting VM1, Since VM7 shares the same HR as VM2 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm7_Context);
        Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm1, VM1);
    }

    /*
     * 1. Restore the lower context for the incoming VM
     * 2. Execute RFH
     */
    __asm("rslcx");
    IFXHV_RFH();
}


#endif

/* ISR routine for HV scheduler when STM event based scheduling mode is selected*/
#if (IFX_CFG_HV2_TIME_BASED_SCHD != 0U)

IFX_INTERRUPT(Hv2_Vm_Scheduler, IFX_CFG_VM2_INTTAB_NUM, IFX_VM0_SCHD_PRIORITY)
{
    /* Setup the CSA region for VM0 if we are doing a function call */
    /*Reg_Temp = 0x370E80u;
     * IFXHV_MTCR(CPU_PCXI, Reg_Temp);
     * IFXHV_MTCR(CPU_FCX, (Reg_Temp+1u));*/

    /* Clear the Interrupt status Flag */
    CPU2_STMHV_VM0_ISCR.B.CMP0IRR = 1U;

    /* Detect VM which was running so far, to save its context before scheduling another VM */
    if (Tc2_Hv.CurrRunningVm == HV_VM1)
    {
        /* Load next VM exeuction ticks */
        CPU2_STMHV_VM0_CMP0.U = CPU2_STMHV_VM0_CMP0.U + g_stmTicks[1];

        /* Save context information of VM1
         * 1. Save PCXI registers of VM1
         */
        Ifx_Hv_saveVmState(&Tc2_Vm1);

        /*
         * VM1 is always scheduled first during start-up. VM2 is scheduled only after 1st execution slot of VM1
         * is complete. Therefore, when schedule enters for the 1st time it shall check if VM2 start-up
         * is already complete.
         */
        if (Tc2_Vm2.State == VM_INIT)
        {
            /* Start VM2 */
            Core2_vm2_start();
        }
        else
        {
            /* RESTORE CONTEXT OF HR2/VM2 since VM3 was previously executing in HR2 */
            Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm2_Context);
            Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm2, VM2);
        }
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM2)
    {
        /* Load next VM exeuction ticks */
        CPU2_STMHV_VM0_CMP0.U = CPU2_STMHV_VM0_CMP0.U + g_stmTicks[2];

        /* Save context information of VM2 */
        Ifx_Hv_saveVmState(&Tc2_Vm2);

        /* STORE the VM2 context in memory before starting VM3, Since VM3 shares the same HR as VM2 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm2_Context);

        /*
         * VM3 is scheduled only after 1st execution slot of VM2
         * is complete. Therefore, when schedule enters for the 1st time it shall check if VM3 start-up
         * is already complete.
         */
        if (Tc2_Vm3.State == VM_INIT)
        {
            Ifx_Ssw_Hv_resetHr2Context(&Tc2_Vm3_Context);
            /* Start VM3 */
            Core2_vm3_start();
        }
        else
        {
            /* RESTORE VM3 context before VM3 re-scheduling */
            Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm3_Context);
            Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm3, VM3);
        }
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM3)
    {
        /* Load next VM exeuction ticks */

        CPU2_STMHV_VM0_CMP0.U = CPU2_STMHV_VM0_CMP0.U + g_stmTicks[3];

        /* Save context information of VM3 */
        Ifx_Hv_saveVmState(&Tc2_Vm3);

        /* STORE the VM3 context in memory before starting VM4, Since VM4 shares the same HR as VM3 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm3_Context);

        /*
         * VM4 is scheduled only after 1st execution slot of VM3
         * is complete. Therefore, when schedule enters for the 1st time it shall check if VM4 start-up
         * is already complete.
         */
        if (Tc2_Vm4.State == VM_INIT)
        {
            Ifx_Ssw_Hv_resetHr2Context(&Tc2_Vm4_Context);
            /* Start VM4 */
            Core2_vm4_start();
        }
        else
        {
            /* RESTORE VM4 context before VM4 re-scheduling */
            Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm4_Context);
            Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm4, VM4);
        }
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM4)
    {
        /* Load next VM exeuction ticks */
        CPU2_STMHV_VM0_CMP0.U = CPU2_STMHV_VM0_CMP0.U + g_stmTicks[4];

        /* Save context information of VM4 */
        Ifx_Hv_saveVmState(&Tc2_Vm4);

        /* STORE the VM4 context in memory before starting VM5, Since VM5 shares the same HR as VM2 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm4_Context);

        /*
         * VM5 is scheduled only after 1st execution slot of VM4
         * is complete. Therefore, when schedule enters for the 1st time it shall check if VM5 start-up
         * is already complete.
         */
        if (Tc2_Vm5.State == VM_INIT)
        {
            Ifx_Ssw_Hv_resetHr2Context(&Tc2_Vm5_Context);
            /* Start VM5 */
            Core2_vm5_start();
        }
        else
        {
            /* RESTORE VM5 context before VM5 re-scheduling */
            Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm5_Context);
            Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm5, VM5);
        }
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM5)
    {
        /* Load next VM exeuction ticks */
        CPU2_STMHV_VM0_CMP0.U = CPU2_STMHV_VM0_CMP0.U + g_stmTicks[5];
        /* Save context information of VM5 */
        Ifx_Hv_saveVmState(&Tc2_Vm5);

        /* STORE the VM5 context in memory before starting VM6, Since VM6 shares the same HR as VM5 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm5_Context);

        /*
         * VM6 is scheduled only after 1st execution slot of VM5
         * is complete. Therefore, when schedule enters for the 1st time it shall check if VM6 start-up
         * is already complete.
         */
        if (Tc2_Vm6.State == VM_INIT)
        {
            Ifx_Ssw_Hv_resetHr2Context(&Tc2_Vm6_Context);
            /* Start VM6 */
            Core2_vm6_start();
        }
        else
        {
            /* RESTORE VM6 context before VM6 re-scheduling */
            Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm6_Context);
            Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm6, VM6);
        }
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM6)
    {
        /* Load next VM exeuction ticks */
        CPU2_STMHV_VM0_CMP0.U = CPU2_STMHV_VM0_CMP0.U + g_stmTicks[6];

        /* Save context information of VM6 */
        Ifx_Hv_saveVmState(&Tc2_Vm6);

        /* STORE the VM6 context in memory before starting VM7, Since VM7 shares the same HR as VM6 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm6_Context);

        /*
         * VM7 is scheduled only after 1st execution slot of VM6
         * is complete. Therefore, when schedule enters for the 1st time it shall check if VM7 start-up
         * is already complete.
         */
        if (Tc2_Vm7.State == VM_INIT)
        {
            Ifx_Ssw_Hv_resetHr2Context(&Tc2_Vm7_Context);
            /* Start VM7 */
            Core2_vm7_start();
        }
        else
        {
            /* RESTORE VM7 context before VM7 re-scheduling */
            Ifx_Ssw_Hv_restoreHr2Context(&Tc2_Vm7_Context);
            Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm7, VM7);
        }
    }
    else if (Tc2_Hv.CurrRunningVm == HV_VM7)
    {
        /* Load next VM exeuction ticks */
        CPU2_STMHV_VM0_CMP0.U = CPU2_STMHV_VM0_CMP0.U + g_stmTicks[0];

        /* Save context information of VM7 */
        Ifx_Hv_saveVmState(&Tc2_Vm7);

        /* STORE the VM7 context in memory before starting VM1, Since VM7 shares the same HR as VM2 i.e HR2 */
        Ifx_Ssw_Hv_saveHr2Context(&Tc2_Vm7_Context);
        Ifx_Hv_restoreVmState(&Tc2_Hv, &Tc2_Vm1, VM1);
    }

    /*
     * 1. Restore the lower context for the incoming VM
     * 2. Execute RFH
     */
    __asm("rslcx");
    IFXHV_RFH();
}
#endif
