/**********************************************************************************************************************
 * \file  dwmac_qos.c
 * \copyright Copyright (C) Infineon Technologies AG 2019
 *
 * Use of this file is subject to the terms of use agreed between (i) you or the company in which ordinary course of
 * business you are acting and (ii) Infineon Technologies AG or its licensees. If and as long as no such terms of use
 * are agreed, use of this file is subject to following:
 *
 * Boost Software License - Version 1.0 - August 17th, 2003
 *
 * Permission is hereby granted, free of charge, to any person or organization obtaining a copy of the software and
 * accompanying documentation covered by this license (the "Software") to use, reproduce, display, distribute, execute,
 * and transmit the Software, and to prepare derivative works of the Software, and to permit third-parties to whom the
 * Software is furnished to do so, all subject to the following:
 *
 * The copyright notices in the Software and this entire statement, including the above license grant, this restriction
 * and the following disclaimer, must be included in all copies of the Software, in whole or in part, and all
 * derivative works of the Software, unless such copies or derivative works are solely in the form of
 * machine-executable object code generated by a source language processor.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE
 * WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
 * COPYRIGHT HOLDERS OR ANYONE DISTRIBUTING THE SOFTWARE BE LIABLE FOR ANY DAMAGES OR OTHER LIABILITY, WHETHER IN
 * CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
 * IN THE SOFTWARE.
 *********************************************************************************************************************/

#include "dwmac_qos.h"

#include "Scu/Std/IfxScuCcu.h"
#include "Src/Std/IfxSrc.h"

#include <string.h>
#include <stdlib.h>

/* CSR Frequency Access Defines*/
#define GETH_MAC_CSR_F_35M  (35000000U)
#define GETH_MAC_CSR_F_60M  (60000000U)
#define GETH_MAC_CSR_F_100M (100000000U)
#define GETH_MAC_CSR_F_150M (150000000U)
#define GETH_MAC_CSR_F_250M (250000000U)
#define GETH_MAC_CSR_F_300M (300000000U)

/* MDC Clock Selection define*/
#define	GETH_MAC_CSR_60_100M	0x0	/* MDC = clk_scr_i/42 */
#define	GETH_MAC_CSR_100_150M	0x1	/* MDC = clk_scr_i/62 */
#define	GETH_MAC_CSR_20_35M	    0x2	/* MDC = clk_scr_i/16 */
#define	GETH_MAC_CSR_35_60M	    0x3	/* MDC = clk_scr_i/26 */
#define	GETH_MAC_CSR_150_250M	0x4	/* MDC = clk_scr_i/102 */
#define	GETH_MAC_CSR_250_300M	0x5	/* MDC = clk_scr_i/122 */

/* MDIO defines */
#define GETH_MAC_MDIO_MAX_RETRIES   0xffffffff
#define GETH_MAC_MDIO_BUSY			(IFX_GETH_MAC_MDIO_ADDRESS_GB_MSK << IFX_GETH_MAC_MDIO_ADDRESS_GB_OFF)
#define GETH_MAC_MDIO_WRITE			(1 << IFX_GETH_MAC_MDIO_ADDRESS_GOC_0_OFF)
#define GETH_MAC_MDIO_READ			(3 << IFX_GETH_MAC_MDIO_ADDRESS_GOC_0_OFF)
#define GETH_MAC_MDIO_OP_MSK		((IFX_GETH_MAC_MDIO_ADDRESS_GOC_0_MSK << IFX_GETH_MAC_MDIO_ADDRESS_GOC_0_OFF) | (IFX_GETH_MAC_MDIO_ADDRESS_GOC_1_MSK << IFX_GETH_MAC_MDIO_ADDRESS_GOC_1_OFF))

/* DMA descriptor bits for RX normal descriptor (read format) */
#define DWCEQOS_DMA_RDES3_OWN     BIT(31)
#define DWCEQOS_DMA_RDES3_INTE    BIT(30)
#define DWCEQOS_DMA_RDES3_BUF1V   BIT(24)

/* DMA descriptor bits for RX normal descriptor (write back format) */
#define DWCEQOS_DMA_RDES1_IPCE    BIT(7)
#define DWCEQOS_DMA_RDES1_PMT(x)  ((x) & 0xF00)
#define DWCEQOS_DMA_RDES1_PFT     BIT(12)
#define DWCEQOS_DMA_RDES1_PV      BIT(13)
#define DWCEQOS_DMA_RDES1_TSA     BIT(14)
#define DWCEQOS_DMA_RDES1_TD      BIT(15)

#define DWCEQOS_DMA_RDES3_FD      BIT(29)
#define DWCEQOS_DMA_RDES3_LD      BIT(28)
#define DWCEQOS_DMA_RDES3_ES      BIT(15)
#define DWCEQOS_DMA_RDES3_PL(x)   ((x) & 0x7fff)

#define GETH_DEFAULT_ADDEND         (0x80000000UL)
#define NANOSECONDS_PER_SECOND      (1000000000ULL)

/* Check if the event passed is a normal event */
static inline boolean ETH_MAC_IsNormalEvent(uint32 event)
{
  return (boolean)((event & ((uint32)ETH_DMA_EVENT_TRANSMIT |
                             (uint32)ETH_DMA_EVENT_TRANSMIT_BUFFER_UNAVAILABLE |
                             (uint32)ETH_DMA_EVENT_RECEIVE |
                             (uint32)ETH_DMA_EVENT_EARLY_RECEIVE)) != 0);
}

/* Check if the event passed is an abnormal event */
static inline boolean ETH_MAC_IsAbnormalEvent(uint32 event)
{
   return (boolean)((event & ((uint32)ETH_DMA_EVENT_TRANSMIT_PROCESS_STOPPED |
                              (uint32)ETH_DMA_EVENT_RECEIVE_BUFFER_UNAVAILABLE |
                              (uint32)ETH_DMA_EVENT_RECEIVE_PROCESS_STOPPED |
                              (uint32)ETH_DMA_EVENT_EARLY_TRANSMIT |
                              (uint32)ETH_DMA_EVENT_BUS_ERROR |
                              (uint32)ETH_DMA_EVENT_CONTEXT_DESC_ERROR)) != 0);
}

static inline sint32 ETH_MAC_WaitOnCondition(volatile uint32 *const reg_addr, uint32 reg_mask, uint32 cond, uint32 timeout)
{
  while (((*reg_addr & reg_mask) != cond) && --timeout);

  if (timeout)
  {
    return 0;
  }

  return -1;
}

static inline boolean ETH_MAC_IsModuleEnabled(Ifx_GETH *const regs)
{
  return (regs->CLC.B.DISS == 0) ? TRUE : FALSE;
}

static void IfxGeth_mtl_setRxQueueOperationMode(Ifx_GETH *gethSFR, IfxGeth_RxMtlQueue queueId, ETH_MTL_RXQ_OPERATION_MODE_t mode)
{
  Ifx_GETH_MTL_RXQ *p = (Ifx_GETH_MTL_RXQ *)((uint32)&gethSFR->MTL_RXQ0 + (0x40 * queueId));
  p->OPERATION_MODE.U = mode.raw;
}

static void IfxGeth_mtl_setTxQueueOperationMode(Ifx_GETH *gethSFR, IfxGeth_TxMtlQueue queueId, ETH_MTL_TXQ_OPERATION_MODE_t mode)
{
  Ifx_GETH_MTL_TXQ *p = (Ifx_GETH_MTL_TXQ *)((uint32)&gethSFR->MTL_TXQ0 + (0x40 * queueId));
  p->OPERATION_MODE.U = mode.raw;
}

static void IfxGeth_mtl_flushTxQueue(Ifx_GETH *gethSFR, IfxGeth_TxMtlQueue queueId)
{
  Ifx_GETH_MTL_TXQ *p = (Ifx_GETH_MTL_TXQ *)((uint32)&gethSFR->MTL_TXQ0 + (0x40 * queueId));
  p->OPERATION_MODE.B.FTQ = TRUE;
}

static void IfxGeth_mtl_setTxQueueSchedAlgorithm(Ifx_GETH *gethSFR, IfxGeth_TxMtlQueue queueId, ETH_MTL_TXQ_ETS_CONTROL_t control)
{
  if (queueId > 0)
  {
    Ifx_GETH_MTL_TXQ *p = (Ifx_GETH_MTL_TXQ *)((uint32)&gethSFR->MTL_TXQ1 + (0x40 * (queueId -1)));
    p->ETS_CONTROL.U = control.raw;
  }
}

static void IfxGeth_mtl_setTxQueueIdleSlopeCredit(Ifx_GETH *gethSFR, IfxGeth_TxMtlQueue queueId, uint32 avb_idle_slope)
{
  if (queueId > 0)
  {
    Ifx_GETH_MTL_TXQ *p = (Ifx_GETH_MTL_TXQ *)((uint32)&gethSFR->MTL_TXQ1 + (0x40 * (queueId -1)));
    p->QUANTUM_WEIGHT.B.ISCQW = avb_idle_slope;
  }
}

static void IfxGeth_mtl_setTxQueueSendSlopeCredit(Ifx_GETH *gethSFR, IfxGeth_TxMtlQueue queueId, uint32  avb_send_slope)
{
  if (queueId > 0)
  {
    Ifx_GETH_MTL_TXQ *p = (Ifx_GETH_MTL_TXQ *)((uint32)&gethSFR->MTL_TXQ1 + (0x40 * (queueId -1)));
    p->SENDSLOPECREDIT.B.SSC = avb_send_slope;
  }
}

static void IfxGeth_mtl_setTxQueueHighCredit(Ifx_GETH *gethSFR, IfxGeth_TxMtlQueue queueId, uint32 avb_high_credit)
{
  if (queueId > 0)
  {
    Ifx_GETH_MTL_TXQ *p = (Ifx_GETH_MTL_TXQ *)((uint32)&gethSFR->MTL_TXQ1 + (0x40 * (queueId -1)));
    p->HICREDIT.B.HC = avb_high_credit;
  }
}

static void IfxGeth_mtl_setTxQueueLowCredit(Ifx_GETH *gethSFR, IfxGeth_TxMtlQueue queueId, uint32 avb_low_credit)
{
  if (queueId > 0)
  {
    Ifx_GETH_MTL_TXQ *p = (Ifx_GETH_MTL_TXQ *)((uint32)&gethSFR->MTL_TXQ1 + (0x40 * (queueId -1)));
    p->LOCREDIT.B.LC = avb_low_credit;
  }
}

static void IfxGeth_mtl_setTxQueueWeight(Ifx_GETH *gethSFR, IfxGeth_TxMtlQueue queueId, uint32 weight)
{
  Ifx_GETH_MTL_TXQ *p = (Ifx_GETH_MTL_TXQ *)((uint32)&gethSFR->MTL_TXQ0 + (0x40 * queueId));
  p->QUANTUM_WEIGHT.U = weight;
}

static inline void IfxGeth_mtl_setRxQueueMode(Ifx_GETH *gethSFR, IfxGeth_RxMtlQueue queueId, IfxGeth_RxQueueMode mode)
{
  gethSFR->MAC_RXQ_CTRL0.U |= ((mode & IFX_GETH_MAC_RXQ_CTRL0_RXQ0EN_MSK) << (queueId * 2));
}

static inline void IfxGeth_mtl_setRxQueueRouting(Ifx_GETH *gethSFR, ETH_MTL_RXQ_ROUTING_t routing, ETH_MTL_RXQ_ROUTING_FAIL_t routing_fail)
{
  gethSFR->MAC_RXQ_CTRL1.U = routing.raw;
  gethSFR->MAC_RXQ_CTRL4.U = routing_fail.raw;
}

sint32 ETH_MAC_Init(ETH_MAC_t *const eth_mac)
{
  ETH_MAC_Enable(eth_mac);
  ETH_MAC_Reset(eth_mac);

  /* MDIO interface */
  ETH_MAC_SetManagmentClockDivider(eth_mac);

  return 0;
}

void ETH_MAC_Reset(ETH_MAC_t *const eth_mac)
{
  Ifx_GETH *const regs = eth_mac->regs;
  uint16 passwd = IfxScuWdt_getCpuWatchdogPassword();

  IfxScuWdt_clearCpuEndinit(passwd);
  regs->KRST0.B.RST = 1;           /* Only if both Kernel reset bits are set a reset is executed */
  regs->KRST1.B.RST = 1;
  IfxScuWdt_setCpuEndinit(passwd);

  while (0 == regs->KRST0.B.RSTSTAT);   /* Wait until reset is executed */

  IfxScuWdt_clearCpuEndinit(passwd);
  regs->KRSTCLR.B.CLR = 1;         /* Clear Kernel reset status bit */
  IfxScuWdt_setCpuEndinit(passwd);
}

void ETH_MAC_Disable(ETH_MAC_t *const eth_mac)
{
  Ifx_GETH *const regs = eth_mac->regs;
  uint16 psw = IfxScuWdt_getCpuWatchdogPassword();

  if (ETH_MAC_IsModuleEnabled(regs)) /* if module is not enabled already */
  {
    IfxScuWdt_clearCpuEndinit(psw); /* clears the endinit protection*/
    regs->CLC.B.DISR = 1;           /* set the enable request */
    IfxScuWdt_setCpuEndinit(psw);   /* sets the endinit protection back on*/
  }

  while (ETH_MAC_IsModuleEnabled(regs));
}

void ETH_MAC_Enable(ETH_MAC_t *const eth_mac)
{
  Ifx_GETH *const regs = eth_mac->regs;
  uint16 psw = IfxScuWdt_getCpuWatchdogPassword();

  IfxScuCcu_setGethFrequency(IfxScuCcu_getSriFrequency() / 2.0F);

  if (!ETH_MAC_IsModuleEnabled(regs)) /* if module is not enabled already */
  {
    IfxScuWdt_clearCpuEndinit(psw);        /* clears the endinit protection*/
    regs->CLC.B.DISR = 0;                  /* set the enable request */
    IfxScuWdt_setCpuEndinit(psw);          /* sets the endinit protection back on*/
  }

  while (!ETH_MAC_IsModuleEnabled(regs));
}

void ETH_MAC_SetPortControl(ETH_MAC_t *const eth_mac, const ETH_MAC_PORT_CTRL_t port_ctrl)
{
  Ifx_GETH *const regs = eth_mac->regs;
  regs->GPCTL.U = port_ctrl.raw;
}

uint32 ETH_MAC_GetPortControl(ETH_MAC_t *const eth_mac)
{
  Ifx_GETH *const regs = eth_mac->regs;
  return regs->GPCTL.U;
}

sint32 ETH_MAC_SetManagmentClockDivider(ETH_MAC_t *const eth_mac)
{
  Ifx_GETH *const regs = eth_mac->regs;
  uint32 csr_clk_rate;
  uint32 divider;

  csr_clk_rate = (uint32)IfxScuCcu_getSpbFrequency();

  if (csr_clk_rate < GETH_MAC_CSR_F_35M)
  {
    divider = GETH_MAC_CSR_20_35M;
  }
  else if (csr_clk_rate < GETH_MAC_CSR_F_60M)
  {
    divider = GETH_MAC_CSR_35_60M;
  }
  else if (csr_clk_rate <= GETH_MAC_CSR_F_100M)
  {
    divider = GETH_MAC_CSR_60_100M;
  }
  else if (csr_clk_rate <= GETH_MAC_CSR_F_150M)
  {
    divider = GETH_MAC_CSR_100_150M;
  }
  else if (csr_clk_rate < GETH_MAC_CSR_F_250M)
  {
    divider = GETH_MAC_CSR_150_250M;
  }
  else if (csr_clk_rate < GETH_MAC_CSR_F_300M)
  {
    divider = GETH_MAC_CSR_250_300M;
  }
  else
  {
    return -1;
  }

  regs->MAC_MDIO_ADDRESS.B.CR = divider;

  return 0;
}

void ETH_MAC_ResetDma(ETH_MAC_t *const mac)
{
  Ifx_GETH *const regs = mac->regs;
  regs->DMA_MODE.B.SWR = 1;

  while (regs->DMA_MODE.B.SWR != 0);
}

void ETH_MAC_SetAddress(ETH_MAC_t *const mac, const ETH_MAC_ADDR_FILTER_t *const addr)
{
  Ifx_GETH *const regs = mac->regs;
  regs->MAC_ADDRESS_HIGH0.U = (addr->config << 16) | (addr->mac_addr[5] << 8) | addr->mac_addr[4];
  regs->MAC_ADDRESS_LOW0.U = addr->mac_addr[0] | (addr->mac_addr[1] << 8) | (addr->mac_addr[2] << 16) | (addr->mac_addr[3] << 24);
}

void ETH_MAC_SetLink(ETH_MAC_t *const mac, ETH_MAC_LINK_SPEED_t speed, ETH_MAC_LINK_MODE_t mode)
{
  Ifx_GETH *const regs = mac->regs;

  regs->MAC_CONFIGURATION.U = (regs->MAC_CONFIGURATION.U & (uint32)~((IFX_GETH_MAC_CONFIGURATION_PS_MSK << IFX_GETH_MAC_CONFIGURATION_PS_OFF) |
                                                                     (IFX_GETH_MAC_CONFIGURATION_FES_MSK << IFX_GETH_MAC_CONFIGURATION_FES_OFF) |
                                                                     (IFX_GETH_MAC_CONFIGURATION_DM_MSK << IFX_GETH_MAC_CONFIGURATION_DM_OFF))) |
                              ((speed << IFX_GETH_MAC_CONFIGURATION_FES_OFF) | (mode << IFX_GETH_MAC_CONFIGURATION_DM_OFF));
}

void ETH_MAC_InitTxQueue(ETH_MAC_t *const eth_mac, uint8 queue)
{
  Ifx_GETH *const regs = eth_mac->regs;
  ETH_MTL_TX_QUEUE_t *const tx_queue = eth_mac->tx_queue[queue];

  if (queue == 0)
  {
    IfxGeth_mtl_setTxQueueWeight(regs, queue, tx_queue->weight);   
  }
  else
  {
    if (tx_queue->ets_control.enable_cbs)
    {
      IfxGeth_mtl_setTxQueueIdleSlopeCredit(regs, queue, tx_queue->avb_idle_slope);
      IfxGeth_mtl_setTxQueueSendSlopeCredit(regs, queue, tx_queue->avb_send_slope);
      IfxGeth_mtl_setTxQueueHighCredit(regs, queue, tx_queue->avb_high_credit);
      IfxGeth_mtl_setTxQueueLowCredit(regs, queue, tx_queue->avb_low_credit);
      IfxGeth_mtl_setTxQueueSchedAlgorithm(regs, queue, tx_queue->ets_control);
    }
    else
    {
      IfxGeth_mtl_setTxQueueWeight(regs, queue, tx_queue->weight);   
    }
  }

  IfxGeth_mtl_flushTxQueue(regs, queue); 
  IfxGeth_mtl_setTxQueueOperationMode(regs, queue, tx_queue->operation_mode);
}

void ETH_MAC_InitTxDmaChannel(ETH_MAC_t *const eth_mac, uint8 channel)
{
  Ifx_GETH *const regs = eth_mac->regs;
  ETH_DMA_CHANNEL_t *const dma_channel = eth_mac->tx_dma_channel[channel];
  volatile IfxGeth_TxDescr *descr = (volatile IfxGeth_TxDescr *)dma_channel->descs;

  /* Init descriptors */
  for (uint32 i = 0; i < dma_channel->desc_cnt; ++i, ++descr)
  {
    descr->TDES0.U = 0;
    descr->TDES1.U = 0;
    descr->TDES2.U = 0;
    descr->TDES3.U = 0;
  }

  regs->DMA_CH[channel].TX_CONTROL.B.TXPBL = 8;
  regs->DMA_CH[channel].TX_CONTROL.B.OSF = 1; // Overlap the transmission of a frame with reading the next frame data from system memory
  regs->DMA_CH[channel].TXDESC_LIST_ADDRESS.U = (uint32)dma_channel->descs;
  regs->DMA_CH[channel].TXDESC_TAIL_POINTER.U = (uint32)dma_channel->descs;
  regs->DMA_CH[channel].TXDESC_RING_LENGTH.U = dma_channel->desc_cnt - 1;

  dma_channel->desc_idx = 0;
  dma_channel->dirty_desc_idx = 0;
}

void ETH_MAC_InitRxQueue(ETH_MAC_t *const eth_mac, uint8 queue)
{
  Ifx_GETH *const regs = eth_mac->regs;
  ETH_MTL_RX_QUEUE_t *const rx_queue = eth_mac->rx_queue[queue];

  IfxGeth_mtl_setRxQueueOperationMode(regs, queue, rx_queue->operation_mode);
  IfxGeth_mtl_setRxQueueDmaChannelMapping(regs, queue, rx_queue->dma_mappping.raw);
  IfxGeth_mac_setVlanPriorityQueueRouting(regs, queue, rx_queue->routing_vlan_prio);
  IfxGeth_mtl_setRxQueueMode(regs, queue, rx_queue->mode); 

}

void ETH_MAC_InitRxDmaChannel(ETH_MAC_t *const eth_mac, uint8 channel)
{
  Ifx_GETH *const regs = eth_mac->regs;
  ETH_DMA_CHANNEL_t *const dma_channel = eth_mac->rx_dma_channel[channel];
  volatile IfxGeth_RxDescr *descr = (volatile IfxGeth_RxDescr *)dma_channel->descs;

  for (uint32 i = 0; i < dma_channel->desc_cnt; ++i, ++descr)
  {
    descr->RDES0.U = (uint32)&(dma_channel->bufs[i * dma_channel->buf_size]);
    descr->RDES1.U = 0;
    descr->RDES2.U = 0; /* buffer2 not used */
    descr->RDES3.U = 0;
    descr->RDES3.R.BUF1V = 1; /* buffer 1 valid */
    descr->RDES3.R.IOC   = 1; /* interrupt enabled */
    descr->RDES3.R.OWN   = 1; /* owned by DMA */
  }

  regs->DMA_CH[channel].RX_CONTROL.B.RXPBL = 8;
  regs->DMA_CH[channel].RX_CONTROL.B.RBSZ_13_Y = (dma_channel->buf_size >> IFX_GETH_DMA_CH_RX_CONTROL_RBSZ_X_0_LEN);
  regs->DMA_CH[channel].RXDESC_LIST_ADDRESS.U = (uint32)dma_channel->descs;
  regs->DMA_CH[channel].RXDESC_TAIL_POINTER.U = (uint32)&dma_channel->descs[dma_channel->desc_cnt];
  regs->DMA_CH[channel].RXDESC_RING_LENGTH.U = dma_channel->desc_cnt - 1;

  dma_channel->desc_idx = 0;
  dma_channel->dirty_desc_idx = 0;
}

void ETH_MAC_UpdateAddressFilterTable(ETH_MAC_t *const mac, const ETH_MAC_ADDR_FILTER_t *const filter_table, uint32 size)
{
  Ifx_GETH *const regs = mac->regs;

  uint32 *p = (uint32 *)&(regs->MAC_ADDRESS_HIGH1.U);
  for (uint32 i = 0; i < size; ++i)
  {
    *p = (filter_table[i].config << 16) | (filter_table[i].mac_addr[5] << 8) | filter_table[i].mac_addr[4];
    ++p;
    *p = (filter_table[i].mac_addr[3] << 24) | (filter_table[i].mac_addr[2] << 16) | (filter_table[i].mac_addr[1] << 8) | filter_table[i].mac_addr[0];
    ++p;
  }
}

void ETH_MAC_UpdateVlanTagFilterTable(ETH_MAC_t *const mac, const ETH_MAC_VLANTAG_FILTER_t *const filter_table, uint32 size)
{
  Ifx_GETH *const regs = mac->regs;

  for (uint32 i = 0; i < size; ++i)
  {
    regs->MAC_VLAN_TAG_DATA.U = filter_table[i].raw;
    regs->MAC_VLAN_TAG_CTRL.B.OFS = i; /* Filter Register's offset */
    regs->MAC_VLAN_TAG_CTRL.B.CT = 0; /* write command */
    
    regs->MAC_VLAN_TAG_CTRL.B.OB = 1;
    while (regs->MAC_VLAN_TAG_CTRL.B.OB != 0)
    {
      __nop();
    }

  }  
}

void ETH_MAC_Start(ETH_MAC_t *const mac, ETH_MAC_LINK_SPEED_t speed, ETH_MAC_LINK_MODE_t mode)
{
  Ifx_GETH *const regs = mac->regs;

  ETH_MAC_SetRGMIIRxDelay(mac, mac->mac_config.rx_skewctrl);
  ETH_MAC_SetRGMIITxDelay(mac, mac->mac_config.tx_skewctrl);

  ETH_MAC_ResetDma(mac);

  ETH_MAC_SetLink(mac, speed, mode);
  ETH_MAC_SetAddress(mac, mac->mac_addr);
  ETH_MAC_UpdateAddressFilterTable(mac, mac->filter_table, mac->filter_table_size);

  /* configure MAC */
  regs->MAC_CONFIGURATION.B.IPC = TRUE; /* Checksum checking offload */

  /* configure DMA */
  regs->DMA_SYSBUS_MODE.B.AAL = TRUE; /* Address-Aligned Beats */
  regs->DMA_SYSBUS_MODE.B.FB = TRUE; /* Fixed Burst Length */
  regs->DMA_MODE.B.DA = 1;  /* RX data transfers have fixed priority over TX transfers on the AHB Master I/F */
  regs->DMA_MODE.B.TXPR = 0;

  /* Queue configuration */
  IfxGeth_mtl_setRxQueueRouting(regs, mac->routing, mac->routing_fail);

  IfxGeth_mtl_setTxSchedulingAlgorithm(regs, mac->mtl_config.tx_sched);

  for (sint32 i = 0; i < ETH_MAC_TX_DMA_CH_CNT; ++i)
  {
    if (mac->tx_dma_channel[i] != NULL)
    {
      ETH_MAC_InitTxDmaChannel(mac, i);
      ETH_MAC_EnableTxDma(mac, i);
    }
  }    

  for (sint32 i = 0; i < ETH_MAC_RX_DMA_CH_CNT; ++i)
  {
    if (mac->rx_dma_channel[i] != NULL)
    {
      ETH_MAC_InitRxDmaChannel(mac, i);
      ETH_MAC_EnableRxDma(mac, i);  
    }
  }    

  for (sint32 i = 0; i < ETH_MAC_TX_QUEUE_CNT; ++i)
  {
    if (mac->tx_queue[i] != NULL)
    {
      ETH_MAC_InitTxQueue(mac, i);
    }
  }    

  IfxGeth_mtl_setRxArbitrationAlgorithm(regs, mac->mtl_config.rx_sched);
  for (sint32 i = 0; i < ETH_MAC_RX_QUEUE_CNT; ++i)
  {
    if (mac->rx_queue[i] != NULL)
    {
      ETH_MAC_InitRxQueue(mac, i);
    }
  }

  /* Mask MMC counter interrupt generation */
  regs->MMC_RX_INTERRUPT_MASK.U = 0xffffffffU;
  regs->MMC_TX_INTERRUPT_MASK.U = 0xffffffffU;
  regs->MMC_IPC_RX_INTERRUPT_MASK.U = 0xffffffffU;

  ETH_MAC_EnableTx(mac);  
  ETH_MAC_EnableRx(mac);
}

void ETH_MAC_Stop(ETH_MAC_t *const mac)
{
  /* Wait for any previous frame transmissions to complete */
  for (sint32 i = 0; i < ETH_MAC_TX_QUEUE_CNT; ++i)
  {
    if (mac->tx_queue[i] != NULL)
    {
      Ifx_GETH_MTL_TXQ_DEBUG status;
      status = IfxGeth_mtl_getTransmitQueueDebugStatus(mac->regs, i);
      while ((status.B.TRCSTS == 1) || (status.B.TXQSTS != 0));
    }
  }

  /* Disable the Transmit DMA channels */
  for (sint32 i = 0; i < ETH_MAC_TX_DMA_CH_CNT; ++i)
  {
    if (mac->tx_dma_channel[i] != NULL)
    {
      ETH_MAC_DisableTxDma(mac, i);  
    }
  }    

  ETH_MAC_DisableRx(mac);  
  ETH_MAC_DisableTx(mac);  

  /* Wait for any previous frame transmissions to complete */
  for (sint32 i = 0; i < ETH_MAC_RX_QUEUE_CNT; ++i)
  {
    if (mac->rx_queue[i] != NULL)
    {
      Ifx_GETH_MTL_RXQ_DEBUG status;
      status = IfxGeth_mtl_getReceiveQueueDebugStatus(mac->regs, i);
      while ((status.B.RXQSTS != 0) || (status.B.PRXQ != 0));
    }
  }

  /* Disable the Receive DMA channels */
  for (sint32 i = 0; i < ETH_MAC_RX_DMA_CH_CNT; ++i)
  {
    if (mac->rx_dma_channel[i] != NULL)
    {
      ETH_MAC_DisableRxDma(mac, i);
    }
  }
}

void ETH_MAC_SetRGMIITxDelay(ETH_MAC_t *const eth_mac, uint32 delay)
{
  Ifx_GETH *const regs = eth_mac->regs;

  regs->SKEWCTL.B.TXCFG = delay & IFX_GETH_SKEWCTL_TXCFG_MSK;
}

void ETH_MAC_SetRGMIIRxDelay(ETH_MAC_t *const eth_mac, uint32 delay)
{
  Ifx_GETH *const regs = eth_mac->regs;

  regs->SKEWCTL.B.RXCFG = delay & IFX_GETH_SKEWCTL_RXCFG_MSK;
}

sint32 ETH_MAC_GetRxDmaFrameSize(ETH_MAC_t *const eth_mac, uint8 channel)
{
  uint32 len;
  ETH_DMA_CHANNEL_t *const dma_channel = eth_mac->rx_dma_channel[channel];
  volatile IfxGeth_RxDescr *descr = (volatile IfxGeth_RxDescr *)&dma_channel->descs[dma_channel->desc_idx];

  if (descr->RDES3.C.OWN != 0)
  {
    len = -1;
  }
  else
  {
    if ((descr->RDES3.C.CTXT !=0) && (descr->RDES3.C.DE != 0))
    {
      len = -2; /* Error descriptor */
    }
    else
    {   
      uint32 rdes3 = descr->RDES3.U;
      uint32 rdes1 = descr->RDES1.U;

      if (((rdes3 & DWCEQOS_DMA_RDES3_ES) != 0U) ||
          ((rdes1 & DWCEQOS_DMA_RDES1_IPCE) != 0U) ||
          ((rdes3 & DWCEQOS_DMA_RDES3_LD) == 0U))
      {
        /* Error, this block is invalid */
        len = -1;
      }
      else
      {
        /* Subtract CRC */
        len = DWCEQOS_DMA_RDES3_PL(rdes3) - 4U;
      }
    }
  }

  return len;
}

uint32 ETH_MAC_GetRxDmaBufferSize(ETH_MAC_t *const eth_mac, uint8 channel)
{
  ETH_DMA_CHANNEL_t *const dma_channel = eth_mac->rx_dma_channel[channel];
  return dma_channel->buf_size;
}

uint32 ETH_MAC_GetTxDmaBufferSize(ETH_MAC_t *const eth_mac, uint8 channel)
{
  ETH_DMA_CHANNEL_t *const dma_channel = eth_mac->tx_dma_channel[channel];
  return dma_channel->buf_size;
}

void ETH_MAC_ReturnRxDmaDescriptor(ETH_MAC_t *const eth_mac, uint8 channel)
{
  ETH_DMA_CHANNEL_t *const dma_channel = eth_mac->rx_dma_channel[channel];
  volatile IfxGeth_RxDescr *descr = (volatile IfxGeth_RxDescr *const)&dma_channel->descs[dma_channel->desc_idx];

  descr->RDES0.U = (uint32)&dma_channel->bufs[dma_channel->desc_idx * dma_channel->buf_size];
  descr->RDES1.U = 0;
  descr->RDES2.U = 0;
  descr->RDES3.U = DWCEQOS_DMA_RDES3_INTE | DWCEQOS_DMA_RDES3_OWN | DWCEQOS_DMA_RDES3_BUF1V;

  dma_channel->desc_idx++;
  if (dma_channel->desc_idx == dma_channel->desc_cnt)
  {
    dma_channel->desc_idx = 0;
  }
}

void ETH_MAC_ReturnTxDmaDescriptor(ETH_MAC_t *const eth_mac, uint8 channel)
{
  ETH_DMA_CHANNEL_t *const dma_channel = eth_mac->tx_dma_channel[channel];
  volatile IfxGeth_TxDescr *const descr = (volatile IfxGeth_TxDescr *const)&dma_channel->descs[dma_channel->desc_idx];

  descr->TDES3.R.OWN = 1;

  dma_channel->desc_idx++;
  if (dma_channel->desc_idx == dma_channel->desc_cnt)
  {
    dma_channel->desc_idx = 0;
  }
}

void ETH_MAC_SetTxDmaBufferSize(ETH_MAC_t *const eth_mac, uint8 channel, uint32 size)
{
  ETH_DMA_CHANNEL_t *const dma_channel = eth_mac->tx_dma_channel[channel];
  volatile IfxGeth_TxDescr *const descr = (volatile IfxGeth_TxDescr *const)&dma_channel->descs[dma_channel->desc_idx];

  descr->TDES0.U = (uint32)&(dma_channel->bufs[dma_channel->desc_idx * dma_channel->buf_size]);
  descr->TDES1.U = 0;
  descr->TDES2.U = 0;
  descr->TDES2.R.B1L = size;
  descr->TDES3.U = 0;
  descr->TDES3.R.FL_TPL = size;
  descr->TDES3.R.CIC_TPL = 3;
  descr->TDES3.R.FD = 1;
  descr->TDES3.R.LD = 1;
}


void ETH_MAC_SetTxDmaDualBufferSize(ETH_MAC_t *const eth_mac, uint8 channel, uint32 *b1, uint32 b1size,uint32 *b2, uint32 b2size)
{
  ETH_DMA_CHANNEL_t *const dma_channel = eth_mac->tx_dma_channel[channel];
  volatile IfxGeth_TxDescr *const descr = (volatile IfxGeth_TxDescr *const)&dma_channel->descs[dma_channel->desc_idx];

  descr->TDES0.U = (uint32)b1; /*(uint32)&(dma_channel->bufs[dma_channel->desc_idx * dma_channel->buf_size]); */
  descr->TDES1.U = (uint32)b2;
  descr->TDES2.U = 0;
  descr->TDES2.R.B1L = b1size;
  descr->TDES2.R.B2L = b2size;
  descr->TDES3.U = 0;
  descr->TDES3.R.FL_TPL = b1size + b2size;
  descr->TDES3.R.CIC_TPL = 3;
  descr->TDES3.R.FD = 1;
  descr->TDES3.R.LD = 1;
}


void ETH_MAC_SetTxDmaDescriptor(ETH_MAC_t *const eth_mac, uint8 channel, IfxGeth_TxDescr *const descr)
{
  ETH_DMA_CHANNEL_t *const dma_channel = eth_mac->tx_dma_channel[channel];
  volatile IfxGeth_TxDescr *const cur_descr = (volatile IfxGeth_TxDescr *const)&dma_channel->descs[dma_channel->desc_idx];

  cur_descr->TDES0.U = descr->TDES0.U;
  cur_descr->TDES1.U = 0;
  cur_descr->TDES2.U = descr->TDES2.U;
  cur_descr->TDES3.U = descr->TDES3.U;
}

void ETH_MAC_EnableTxDmaTimeStamp(ETH_MAC_t *const eth_mac, uint8 channel)
{
  ETH_DMA_CHANNEL_t *const dma_channel = eth_mac->tx_dma_channel[channel];
  volatile IfxGeth_TxDescr *const descr = (volatile IfxGeth_TxDescr *const)&dma_channel->descs[dma_channel->desc_idx];

  descr->TDES2.R.TTSE_TMWD = TRUE;
}

void ETH_MAC_EnableTxDmaInterrupt(ETH_MAC_t *const eth_mac, uint8 channel)
{
  ETH_DMA_CHANNEL_t *const dma_channel = eth_mac->tx_dma_channel[channel];
  volatile IfxGeth_TxDescr *const descr = (volatile IfxGeth_TxDescr *const)&dma_channel->descs[dma_channel->desc_idx];

  descr->TDES2.R.IOC = TRUE;
}

void ETH_MAC_EnableDmaEvent(ETH_MAC_t *const eth_mac, uint8 channel, uint32 event)
{
  Ifx_GETH *const regs = eth_mac->regs;

  if (ETH_MAC_IsNormalEvent(event))
  {
    event |= (uint32)(IFX_GETH_DMA_CH_INTERRUPT_ENABLE_NIE_MSK << IFX_GETH_DMA_CH_INTERRUPT_ENABLE_NIE_OFF);
  }

  if (ETH_MAC_IsAbnormalEvent(event))
  {
    event |= (uint32)(IFX_GETH_DMA_CH_INTERRUPT_ENABLE_AIE_MSK << IFX_GETH_DMA_CH_INTERRUPT_ENABLE_AIE_OFF);
  }

  regs->DMA_CH[channel].INTERRUPT_ENABLE.U = event;
}

void ETH_MAC_DisableDmaEvent(ETH_MAC_t *const eth_mac, uint8 channel, uint32 event)
{
  Ifx_GETH *const regs = eth_mac->regs;

  regs->DMA_CH[channel].INTERRUPT_ENABLE.U &= ~event;
}

void ETH_MAC_ClearDmaEventStatus(ETH_MAC_t *const eth_mac, uint8 channel, uint32 event)
{
  Ifx_GETH *const regs = eth_mac->regs;

  if (regs->DMA_CH[channel].STATUS.B.NIS != 0U)
  {
    /*event |= (uint32)(IFX_GETH_DMA_CH_STATUS_NIS_MSK << IFX_GETH_DMA_CH_STATUS_NIS_OFF); */
  }

  if (regs->DMA_CH[channel].STATUS.B.AIS != 0U)
  {
    /*event |= (uint32)(IFX_GETH_DMA_CH_STATUS_AIS_MSK << IFX_GETH_DMA_CH_STATUS_AIS_OFF); */
  }

  regs->DMA_CH[channel].STATUS.U = event;
}

sint32 ETH_MDIO_Read(ETH_MAC_t *const eth_mac, uint8 addr, uint32 regnum, uint16 *const regval, uint32 timeout)
{
  Ifx_GETH *const regs = eth_mac->regs;

  /* Wait until any existing MII operation is complete */
  if (ETH_MAC_WaitOnCondition((volatile uint32 *const)&regs->MAC_MDIO_ADDRESS, GETH_MAC_MDIO_BUSY, 0, timeout) != 0)
  {
    return -1;
  }

  uint32 temp = (regs->MAC_MDIO_ADDRESS.U & (uint32)~((IFX_GETH_MAC_MDIO_ADDRESS_PA_MSK << IFX_GETH_MAC_MDIO_ADDRESS_PA_OFF) |
                                                      (IFX_GETH_MAC_MDIO_ADDRESS_RDA_MSK << IFX_GETH_MAC_MDIO_ADDRESS_RDA_OFF) |
                                                      GETH_MAC_MDIO_OP_MSK)) | GETH_MAC_MDIO_BUSY | GETH_MAC_MDIO_READ;

  temp |= (addr & IFX_GETH_MAC_MDIO_ADDRESS_PA_MSK) << IFX_GETH_MAC_MDIO_ADDRESS_PA_OFF;

  /* Check IEEE 802.3ae clause 45 addressing mode */
  if (regnum & BIT(31)) 
  {
    /* Get the register address for the given MMD [0-65535] */
	  regs->MAC_MDIO_DATA.U = (regnum & IFX_GETH_MAC_MDIO_DATA_RA_MSK) << IFX_GETH_MAC_MDIO_DATA_RA_OFF;

    /* compose adress register */
    temp |= BITMASK(IFX_GETH_MAC_MDIO_ADDRESS_C45E);
    /* Get the MMD address [0:31] */
    temp |= ((regnum >> IFX_GETH_MAC_MDIO_DATA_RA_LEN) & IFX_GETH_MAC_MDIO_ADDRESS_RDA_MSK) << IFX_GETH_MAC_MDIO_ADDRESS_RDA_OFF;
    regs->MAC_MDIO_ADDRESS.U = temp;

  }
  else
  {
    temp |= (regnum & IFX_GETH_MAC_MDIO_ADDRESS_RDA_MSK) << IFX_GETH_MAC_MDIO_ADDRESS_RDA_OFF;
    regs->MAC_MDIO_ADDRESS.U = temp;
  }
  
  if (ETH_MAC_WaitOnCondition((volatile uint32 *const)&regs->MAC_MDIO_ADDRESS, GETH_MAC_MDIO_BUSY, 0, timeout) != 0)
  {
    return -1;
  }

  *regval = (uint16)regs->MAC_MDIO_DATA.U;
  return 0;
}

sint32 ETH_MDIO_Write(ETH_MAC_t *const eth_mac, uint8 addr, uint32 regnum, uint16 regval, uint32 timeout)
{
  Ifx_GETH *const regs = eth_mac->regs;

  /* Wait until any existing MII operation is complete */
  if (ETH_MAC_WaitOnCondition((volatile uint32 *const)&regs->MAC_MDIO_ADDRESS, GETH_MAC_MDIO_BUSY, 0, timeout) != 0)
  {
    return -1;
  }

  uint32 temp = (regs->MAC_MDIO_ADDRESS.U & (uint32)~((IFX_GETH_MAC_MDIO_ADDRESS_PA_MSK << IFX_GETH_MAC_MDIO_ADDRESS_PA_OFF) |
                                                      (IFX_GETH_MAC_MDIO_ADDRESS_RDA_MSK << IFX_GETH_MAC_MDIO_ADDRESS_RDA_OFF) |
                                                      GETH_MAC_MDIO_OP_MSK)) | GETH_MAC_MDIO_BUSY | GETH_MAC_MDIO_WRITE;

  temp |= (addr & IFX_GETH_MAC_MDIO_ADDRESS_PA_MSK) << IFX_GETH_MAC_MDIO_ADDRESS_PA_OFF;

  /* Check IEEE 802.3ae clause 45 addressing mode */
  if (regnum & BIT(31)) 
  {
    /* Get the register address for the given MMD [0-65535] */
    regs->MAC_MDIO_DATA.U = regval | ((regnum & IFX_GETH_MAC_MDIO_DATA_RA_MSK) << IFX_GETH_MAC_MDIO_DATA_RA_OFF);;

    /* compose adress register */
    temp |= BITMASK(IFX_GETH_MAC_MDIO_ADDRESS_C45E);
    /* Get the MMD address [0:31] */
    temp |= ((regnum >> IFX_GETH_MAC_MDIO_DATA_RA_LEN) & IFX_GETH_MAC_MDIO_ADDRESS_RDA_MSK) << IFX_GETH_MAC_MDIO_ADDRESS_RDA_OFF;
    regs->MAC_MDIO_ADDRESS.U = temp;

  }
  else
  {
    temp |= (regnum & IFX_GETH_MAC_MDIO_ADDRESS_RDA_MSK) << IFX_GETH_MAC_MDIO_ADDRESS_RDA_OFF;
    regs->MAC_MDIO_DATA.U = regval;
    regs->MAC_MDIO_ADDRESS.U = temp;
  }
  

  if (ETH_MAC_WaitOnCondition((volatile uint32 *const)&regs->MAC_MDIO_ADDRESS, GETH_MAC_MDIO_BUSY, 0, timeout) != 0)
  {
    return -1;
  }

  return 0;
}

void ETH_MAC_InitPTP(ETH_MAC_t *const mac, const ETH_MAC_TIMESTAMP_CONFIG_t config, const ETH_MAC_TIME_t *const time)
{
  Ifx_GETH *const regs = mac->regs;

  regs->MAC_INTERRUPT_ENABLE.B.TSIE = 0;
  regs->MAC_TIMESTAMP_CONTROL.U = IFX_GETH_MAC_TIMESTAMP_CONTROL_TSENA_MSK << IFX_GETH_MAC_TIMESTAMP_CONTROL_TSENA_OFF;

  uint32 ssinc;
  if (config.enable_fine_update)
  {
    /* fGETH = Reference Clock for the Time Stamp Update Logic */
    ssinc = ((2 * 256 * NANOSECONDS_PER_SECOND) / IfxScuCcu_getGethFrequency());

    if (config.enable_digital_rollover == 0)
    {
	    /* 0.465ns accuracy */
      ssinc = (ssinc * 1000) / 466;
    }

  }
  else
  {
    /* Program sub-second increment register based on PTP clock frequency = fGETH */
    ssinc = (NANOSECONDS_PER_SECOND * 256) / IfxScuCcu_getGethFrequency();
  }

  regs->MAC_SUB_SECOND_INCREMENT.U = ssinc << IFX_GETH_MAC_SUB_SECOND_INCREMENT_SNSINC_OFF;

  if (config.enable_fine_update)
  {
    regs->MAC_TIMESTAMP_ADDEND.U = GETH_DEFAULT_ADDEND;

    /* Addend register update */
    regs->MAC_TIMESTAMP_CONTROL.B.TSADDREG = 1;
    /* Poll the Timestamp Control register until the bit TSADDREG is cleared */
    while (regs->MAC_TIMESTAMP_CONTROL.B.TSADDREG != 0);

    regs->MAC_TIMESTAMP_CONTROL.U |= IFX_GETH_MAC_TIMESTAMP_CONTROL_TSCFUPDT_MSK << IFX_GETH_MAC_TIMESTAMP_CONTROL_TSCFUPDT_OFF;
  }

  regs->MAC_TIMESTAMP_CONTROL.U |= config.raw;

  if (time != NULL)
  {
    regs->MAC_SYSTEM_TIME_NANOSECONDS_UPDATE.U = time->nanoseconds;
    regs->MAC_SYSTEM_TIME_SECONDS_UPDATE.U = time->seconds;
  }

  regs->MAC_TIMESTAMP_CONTROL.B.TSINIT = 1;
  while (regs->MAC_TIMESTAMP_CONTROL.B.TSINIT != 0);

}

void ETH_MAC_SetPTPTime(ETH_MAC_t *const mac, const ETH_MAC_TIME_t *const time)
{
  Ifx_GETH *const regs = mac->regs;

  regs->MAC_SYSTEM_TIME_NANOSECONDS_UPDATE.U = time->nanoseconds; /* accuracy of 1 ns */
  regs->MAC_SYSTEM_TIME_SECONDS_UPDATE.U = time->seconds;

  regs->MAC_TIMESTAMP_CONTROL.B.TSINIT = 1;
  while (regs->MAC_TIMESTAMP_CONTROL.B.TSINIT != 0);
}

void ETH_MAC_GetPTPTime(ETH_MAC_t *const mac, ETH_MAC_TIME_t *const time)
{
  Ifx_GETH *const regs = mac->regs;

  time->nanoseconds = regs->MAC_SYSTEM_TIME_NANOSECONDS.U; /* accuracy of 1 ns */
  time->seconds = regs->MAC_SYSTEM_TIME_SECONDS.U;
}

sint32 ETH_MAC_GetTxTimeStamp(ETH_MAC_t *const mac, uint8 channel, ETH_MAC_TIME_t *const time)
{
  ETH_DMA_CHANNEL_t *const dma_channel = mac->tx_dma_channel[channel];
  volatile IfxGeth_TxDescr *const descr = (volatile IfxGeth_TxDescr *const )&dma_channel->descs[dma_channel->dirty_desc_idx];

  if (descr->TDES3.W.OWN != 0)
  {
    return -2;
  }
  else
  {
    if (descr->TDES3.W.TTSS && descr->TDES3.W.LD)
    {
      time->nanoseconds = (sint32)(descr->TDES0.W.TTSL); /* accuracy of 1 ns */
      time->seconds = descr->TDES1.W.TTSH;

      return 0;
    }
    else
    {
      return -1;
    }
  }
}

sint32 ETH_MAC_GetRxTimeStamp(ETH_MAC_t *const mac, uint8 channel, ETH_MAC_TIME_t *const time)
{
  ETH_DMA_CHANNEL_t *const dma_channel = mac->rx_dma_channel[channel];
  volatile IfxGeth_RxDescr *descr = (volatile IfxGeth_RxDescr *const )&dma_channel->descs[dma_channel->desc_idx];

  sint32 status = -1;

  if ((descr->RDES3.W.LD != 0) && (descr->RDES3.W.RS1V != 0))
  {
    if (descr->RDES1.W.TSA != 0)
    {
      /* If time stamp available, go to next descriptor */
      descr++;
      if ((descr->RDES3.C.OWN == 0) && (descr->RDES3.C.CTXT != 0) && (descr->RDES3.C.DE == 0))
      {
        if (!((descr->RDES0.U == 0xffffffff) && (descr->RDES1.U == 0xffffffff)))
        {
          time->nanoseconds = (sint32)(descr->RDES0.C.RTSL); /* accuracy of 1 ns */
          time->seconds = descr->RDES1.C.RTSH;
          status = 0;
        }
      }
    }
  }

  return status;
}

/**
 * stmmac_adjust_freq
 *
 * @ptp: pointer to ptp_clock_info structure
 * @ppb: desired period change in parts ber billion
 *
 * Description: this function will adjust the frequency of hardware clock.
 */
void ETH_MAC_AdjustAddend(ETH_MAC_t *const mac, sint32 correction)
{
  Ifx_GETH *const regs = mac->regs;
  uint32 addend;
  uint32 diff;
  sint32 neg_adj = 0;
  uint64 adj;

  if (correction < 0) 
  {
		neg_adj = 1;
		correction = -correction;
	}

  addend = GETH_DEFAULT_ADDEND;
  adj = addend;
  adj *= correction;
  diff = adj / NANOSECONDS_PER_SECOND;
  addend = neg_adj ? (addend - diff) : (addend + diff);

  regs->MAC_TIMESTAMP_ADDEND.U = addend;

  /* Addend register update */
  regs->MAC_TIMESTAMP_CONTROL.B.TSADDREG = 1;
  /* Poll the Timestamp Control register until the bit TSADDREG is cleared */
  while (regs->MAC_TIMESTAMP_CONTROL.B.TSADDREG != 0);
}

#define	PTP_DIGITAL_ROLLOVER_MODE	0x3B9ACA00	/* 10e9-1 ns */
#define	PTP_BINARY_ROLLOVER_MODE	0x80000000	/* ~0.466 ns */

void ETH_MAC_AdjustTime(ETH_MAC_t *const mac, ETH_MAC_TIME_t *const time, uint32 add_sub)
{
  Ifx_GETH *const regs = mac->regs;

  if (add_sub)
  {
    /* If the new sec value needs to be subtracted with
		 * the system time, then MAC_STSUR reg should be
		 * programmed with (2^32 â€“ <new_sec_value>)
     */
    time->seconds = -time->seconds;
    if (regs->MAC_TIMESTAMP_CONTROL.B.TSCTRLSSR)
    {
      time->nanoseconds = PTP_DIGITAL_ROLLOVER_MODE - time->nanoseconds;
    }
    else
    {
      time->nanoseconds = PTP_BINARY_ROLLOVER_MODE - time->nanoseconds;
    }
  }

  regs->MAC_SYSTEM_TIME_SECONDS_UPDATE.U = time->seconds;
  regs->MAC_SYSTEM_TIME_NANOSECONDS_UPDATE.U = (add_sub << IFX_GETH_MAC_SYSTEM_TIME_NANOSECONDS_UPDATE_ADDSUB_OFF) | time->nanoseconds; /* accuracy of 1 ns */

  regs->MAC_TIMESTAMP_CONTROL.B.TSUPDT = 1;
  while (regs->MAC_TIMESTAMP_CONTROL.B.TSUPDT != 0);
}

void ETH_MAC_EnableGlobalServiceRequest(ETH_MAC_t *const eth_mac, IfxSrc_Tos typOfService, Ifx_Priority priority)
{
  volatile Ifx_SRC_SRCR *src = IfxGeth_getSrcPointer(eth_mac->regs, IfxGeth_ServiceRequest_0);
  IfxSrc_init(src, typOfService, priority);
  IfxSrc_enable(src);
}

void ETH_MAC_EnablePpsServiceRequest(ETH_MAC_t *const eth_mac, IfxSrc_Tos typOfService, Ifx_Priority priority)
{
  volatile Ifx_SRC_SRCR *src = IfxGeth_getSrcPointer(eth_mac->regs, IfxGeth_ServiceRequest_1);
  IfxSrc_init(src, typOfService, priority);
  IfxSrc_enable(src);
}

sint32 ETH_MAC_FlexPPSConfig(ETH_MAC_t *const eth_mac, uint8 idx, const ETH_FLEX_PPS_CFG_t *const config)
{
  (void)idx;  

  Ifx_GETH *const regs = eth_mac->regs;

  if (config == NULL)
  {
    return -1;
  }

  if (regs->MAC_PPS0_TARGET_TIME_NANOSECONDS.B.TRGTBUSY0)
  {
    return -2;
  }

  if (regs->MAC_PPS_CONTROL.B.PPSCTRL_PPSCMD != 0)
  {
    return -3;
  }

  uint32 val = 0;
  val = (IFX_GETH_MAC_PPS_CONTROL_PPSEN0_MSK << IFX_GETH_MAC_PPS_CONTROL_PPSEN0_OFF) | // Flexible PPS Output Mode Enable
        (0x2 << IFX_GETH_MAC_PPS_CONTROL_TRGTMODSEL0_OFF) | // Target Time registers are programmed for generating the interrupt event and starting or stopping the PPS0 output signal generation
        (config->cmd << IFX_GETH_MAC_PPS_CONTROL_PPSCTRL_PPSCMD_OFF);

  regs->MAC_PPS0_TARGET_TIME_SECONDS.U = config->start.seconds;
  regs->MAC_PPS0_TARGET_TIME_NANOSECONDS.U = config->start.nanoseconds;

  regs->MAC_PPS0_INTERVAL.U = ((config->interval * 256) / (regs->MAC_SUB_SECOND_INCREMENT.U >> IFX_GETH_MAC_SUB_SECOND_INCREMENT_SNSINC_OFF));
  regs->MAC_PPS0_WIDTH.U = ((config->width * 256) / (regs->MAC_SUB_SECOND_INCREMENT.U >> IFX_GETH_MAC_SUB_SECOND_INCREMENT_SNSINC_OFF));

  regs->MAC_PPS_CONTROL.U = val;

  return 0;
}

sint32 ETH_MAC_PPSConfig(ETH_MAC_t *const eth_mac, uint8 idx, uint32 freq_ctrl)
{
  (void)idx;

  Ifx_GETH *const regs = eth_mac->regs;

  uint32 val = freq_ctrl & IFX_GETH_MAC_PPS_CONTROL_PPSCTRL_PPSCMD_MSK;

  regs->MAC_PPS_CONTROL.U = val;

  return 0;
}


void ETH_MAC_EnableRxDmaServiceRequest(ETH_MAC_t *const eth_mac, uint8 channel, IfxSrc_Tos typOfService, Ifx_Priority priority)
{
  volatile Ifx_SRC_SRCR *src = IfxGeth_getSrcPointer(eth_mac->regs, channel + IfxGeth_ServiceRequest_6);
  IfxSrc_init(src, typOfService, priority);
  IfxSrc_enable(src);
}

void ETH_MAC_EnableTxDmaServiceRequest(ETH_MAC_t *const eth_mac, uint8 channel, IfxSrc_Tos typOfService, Ifx_Priority priority)
{
  volatile Ifx_SRC_SRCR *src = IfxGeth_getSrcPointer(eth_mac->regs, channel + IfxGeth_ServiceRequest_2);
  IfxSrc_init(src, typOfService, priority);
  IfxSrc_enable(src);
}

void ETH_MAC_MMC_Control(ETH_MAC_t *const eth_mac, sint32 mode)
{
  Ifx_GETH *const regs = eth_mac->regs;
  uint32 value;

  value = regs->MMC_CONTROL.U;
  value |= mode & 0x3F;
  regs->MMC_CONTROL.U = value;
}

/* This reads the MAC core counters (if actaully supported).
 * by default the MMC core is programmed to reset each
 * counter after a read. So all the field of the mmc struct
 * have to be incremented.
 */
void ETH_MAC_MMC_Read(ETH_MAC_t *const eth_mac, ETH_MAC_MMC_t *mmc)
{
  Ifx_GETH *const regs = eth_mac->regs;

  mmc->tx_octetcount_gb = regs->TX_OCTET_COUNT_GOOD_BAD.U;
  mmc->tx_framecount_gb = regs->TX_PACKET_COUNT_GOOD_BAD.U;
  mmc->tx_broadcastframe_g = regs->TX_BROADCAST_PACKETS_GOOD.U;
  mmc->tx_multicastframe_g = regs->TX_MULTICAST_PACKETS_GOOD.U;
  mmc->tx_64_octets_gb = regs->TX_64OCTETS_PACKETS_GOOD_BAD.U;
  mmc->tx_65_to_127_octets_gb = regs->TX_65TO127OCTETS_PACKETS_GOOD_BAD.U;
  mmc->tx_128_to_255_octets_gb = regs->TX_128TO255OCTETS_PACKETS_GOOD_BAD.U;
  mmc->tx_256_to_511_octets_gb = regs->TX_256TO511OCTETS_PACKETS_GOOD_BAD.U;
  mmc->tx_512_to_1023_octets_gb = regs->TX_512TO1023OCTETS_PACKETS_GOOD_BAD.U;
  mmc->tx_1024_to_max_octets_gb = regs->TX_1024TOMAXOCTETS_PACKETS_GOOD_BAD.U;
  mmc->tx_unicast_gb = regs->TX_UNICAST_PACKETS_GOOD_BAD.U;
  mmc->tx_multicast_gb = regs->TX_MULTICAST_PACKETS_GOOD_BAD.U;
  mmc->tx_broadcast_gb = regs->TX_BROADCAST_PACKETS_GOOD_BAD.U;
  mmc->tx_underflow_error = regs->TX_UNDERFLOW_ERROR_PACKETS.U;
  mmc->tx_singlecol_g = regs->TX_SINGLE_COLLISION_GOOD_PACKETS.U;
  mmc->tx_multicol_g = regs->TX_MULTIPLE_COLLISION_GOOD_PACKETS.U;
  mmc->tx_deferred = regs->TX_DEFERRED_PACKETS.U;
  mmc->tx_latecol = regs->TX_LATE_COLLISION_PACKETS.U;
  mmc->tx_exesscol = regs->TX_EXCESSIVE_COLLISION_PACKETS.U;
  mmc->tx_carrier_error = regs->TX_CARRIER_ERROR_PACKETS.U;
  mmc->tx_octetcount_g = regs->TX_OCTET_COUNT_GOOD.U;
  mmc->tx_framecount_g = regs->TX_PACKET_COUNT_GOOD.U;
  mmc->tx_excessdef = regs->TX_EXCESSIVE_DEFERRAL_ERROR.U;
  mmc->tx_pause_frame = regs->TX_PAUSE_PACKETS.U;
  mmc->tx_vlan_frame_g = regs->TX_VLAN_PACKETS_GOOD.U;
  mmc->tx_oversize_frames_g = regs->TX_OSIZE_PACKETS_GOOD.U;

  /* MMC RX counter registers */
  mmc->rx_framecount_gb = regs->RX_PACKETS_COUNT_GOOD_BAD.U;
  mmc->rx_octetcount_gb = regs->RX_OCTET_COUNT_GOOD_BAD.U;
  mmc->rx_octetcount_g = regs->RX_OCTET_COUNT_GOOD.U;
  mmc->rx_broadcastframe_g = regs->RX_BROADCAST_PACKETS_GOOD.U;
  mmc->rx_multicastframe_g = regs->RX_MULTICAST_PACKETS_GOOD.U;
  mmc->rx_crc_error = regs->RX_CRC_ERROR_PACKETS.U;
  mmc->rx_align_error = regs->RX_ALIGNMENT_ERROR_PACKETS.U;
  mmc->rx_run_error = regs->RX_RUNT_ERROR_PACKETS.U;
  mmc->rx_jabber_error = regs->RX_JABBER_ERROR_PACKETS.U;
  mmc->rx_undersize_g = regs->RX_UNDERSIZE_PACKETS_GOOD.U;
  mmc->rx_oversize_g = regs->RX_OVERSIZE_PACKETS_GOOD.U;
  mmc->rx_64_octets_gb = regs->RX_64OCTETS_PACKETS_GOOD_BAD.U;
  mmc->rx_65_to_127_octets_gb = regs->RX_65TO127OCTETS_PACKETS_GOOD_BAD.U;
  mmc->rx_128_to_255_octets_gb = regs->RX_128TO255OCTETS_PACKETS_GOOD_BAD.U;
  mmc->rx_256_to_511_octets_gb = regs->RX_256TO511OCTETS_PACKETS_GOOD_BAD.U;
  mmc->rx_512_to_1023_octets_gb = regs->RX_512TO1023OCTETS_PACKETS_GOOD_BAD.U;
  mmc->rx_1024_to_max_octets_gb = regs->RX_1024TOMAXOCTETS_PACKETS_GOOD_BAD.U;
  mmc->rx_unicast_g = regs->RX_UNICAST_PACKETS_GOOD.U;
  mmc->rx_length_error = regs->RX_LENGTH_ERROR_PACKETS.U;
  mmc->rx_autofrangetype = regs->RX_OUT_OF_RANGE_TYPE_PACKETS.U;
  mmc->rx_pause_frames = regs->RX_PAUSE_PACKETS.U;
  mmc->rx_fifo_overflow = regs->RX_FIFO_OVERFLOW_PACKETS.U;
  mmc->rx_vlan_frames_gb = regs->RX_VLAN_PACKETS_GOOD_BAD.U;
  mmc->rx_watchdog_error = regs->RX_WATCHDOG_ERROR_PACKETS.U;
  mmc->rx_receive_frames_error = regs->RX_RECEIVE_ERROR_PACKETS.U;
  mmc->rx_control_frames_g = regs->RX_CONTROL_PACKETS_GOOD.U;

  /* IPv4 */
  mmc->rx_ipv4_gd = regs->RXIPV4_GOOD_PACKETS.U;
  mmc->rx_ipv4_hderr = regs->RXIPV4_HEADER_ERROR_PACKETS.U;
  mmc->rx_ipv4_nopay = regs->RXIPV4_NO_PAYLOAD_PACKETS.U;
  mmc->rx_ipv4_frag = regs->RXIPV4_FRAGMENTED_PACKETS.U;
  mmc->rx_ipv4_udsbl = regs->RXIPV4_UDP_CHECKSUM_DISABLED_PACKETS.U;

  mmc->rx_ipv4_gd_octets = regs->RXIPV4_GOOD_OCTETS.U;
  mmc->rx_ipv4_hderr_octets = regs->RXIPV4_HEADER_ERROR_OCTETS.U;
  mmc->rx_ipv4_nopay_octets = regs->RXIPV4_NO_PAYLOAD_OCTETS.U;
  mmc->rx_ipv4_frag_octets = regs->RXIPV4_FRAGMENTED_OCTETS.U;
  mmc->rx_ipv4_udsbl_octets = regs->RXIPV4_UDP_CHECKSUM_DISABLE_OCTETS.U;

  /* IPV6 */
  mmc->rx_ipv6_gd_octets = regs->RXIPV6_GOOD_OCTETS.U;
  mmc->rx_ipv6_hderr_octets = regs->RXIPV6_HEADER_ERROR_OCTETS.U;
  mmc->rx_ipv6_nopay_octets = regs->RXIPV6_NO_PAYLOAD_OCTETS.U;

  mmc->rx_ipv6_gd = regs->RXIPV6_GOOD_PACKETS.U;
  mmc->rx_ipv6_hderr = regs->RXIPV6_HEADER_ERROR_PACKETS.U;
  mmc->rx_ipv6_nopay = regs->RXIPV6_NO_PAYLOAD_PACKETS.U;

  /* Protocols */
  mmc->rx_udp_gd = regs->RXUDP_GOOD_PACKETS.U;
  mmc->rx_udp_err = regs->RXUDP_ERROR_PACKETS.U;
  mmc->rx_tcp_gd = regs->RXTCP_GOOD_PACKETS.U;
  mmc->rx_tcp_err = regs->RXTCP_ERROR_PACKETS.U;
  mmc->rx_icmp_gd = regs->RXICMP_GOOD_PACKETS.U;
  mmc->rx_icmp_err = regs->RXICMP_ERROR_PACKETS.U;

  mmc->rx_udp_gd_octets = regs->RXUDP_GOOD_OCTETS.U;
  mmc->rx_udp_err_octets = regs->RXUDP_ERROR_OCTETS.U;
  mmc->rx_tcp_gd_octets = regs->RXTCP_GOOD_OCTETS.U;
  mmc->rx_tcp_err_octets = regs->RXTCP_ERROR_OCTETS.U;
  mmc->rx_icmp_gd_octets = regs->RXICMP_GOOD_OCTETS.U;
  mmc->rx_icmp_err_octets = regs->RXICMP_ERROR_OCTETS.U;
}
